---
layout: post
title: 'Everything generates data: Capturing WIFI anonymous traffic using Raspberry
  Pi and WSO2 BAM (Part II)'
date: 2016-02-04 18:22:57.000000000 +01:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Big Data
- IoT
- Security
tags:
- Cassandra
- CEP
- Kismet
- Privacy
- Raspberry Pi
meta:
  _wpcom_is_markdown: '1'
  _edit_last: '578869'
  geo_public: '0'
  _publicize_job_id: '19464055860'
  publicize_google_plus_url: https://plus.google.com/+RogerCarhuatocto/posts/FHhvLnyzkpw
  _publicize_done_5110107: '1'
  _wpas_done_5053089: '1'
  publicize_linkedin_url: https://www.linkedin.com/updates?discuss=&scope=6985267&stype=M&topic=6101062206772826113&type=U&a=OSXn
  _publicize_done_5110110: '1'
  _wpas_done_5053092: '1'
  _publicize_done_external: a:1:{s:7:"twitter";a:1:{i:13849;s:54:"https://twitter.com/Chilcano/status/695296591981256704";}}
  _publicize_done_17477: '1'
  _wpas_done_13849: '1'
  publicize_twitter_user: Chilcano
  _wpas_skip_5053089: '1'
author:
  login: rcarhuatocto
  email: roger@intix.info
  display_name: Roger CARHUATOCTO
  first_name: ''
  last_name: ''
permalink: "/2016/02/04/everything-generates-data-capturing-wifi-anonymous-traffic-using-raspberry-pi-and-wso2-bam-part-ii/"
---
<p>After configuring the Raspberry Pi to capture WIFI/802.11 traffic (<a href="https://holisticsecurity.wordpress.com/2016/02/02/everything-generates-data-capturing-wifi-anonymous-traffic-raspberrypi-wso2-part-i">first blog post</a>), we have to store this traffic in a Database (NoSQL and RDBMS).<br />
Because, the idea is to process in real-time and/or batch the stored data.</p>
<p>To capture this type of traffic (WIFI/802.11 traffic) is so difficult for next reasons:</p>
<ul>
<li>Kismet captures 802.11 layer-2 wireless network traffic (Network IP blocks such as TCP, UDP, ARP, and DHCP packets) what should be decoded.</li>
<li>The traffic should be captured and stored in real-time, we have to use a protocol optimized to capture quickly and low latency.</li>
<li>The library that implements that protocol should have low memory footprint, because Kismet will run in a Raspberry Pi.</li>
<li>The protocol to be used should be developer-friendly in both sides (Raspberry Pi side and WSO2 BAM - Apache Cassandra side).</li>
</ul>
<p>Well, in this second blog post I will explain how to solve above difficults.<br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-1-architecture.png" alt="Architecture IoT/BigData – Storing WIFI traffic in Apache Cassandra (WSO2 BAM and Apache Thrift)" title="Architecture IoT/BigData– Storing WIFI traffic in Apache Cassandra (WSO2 BAM and Apache Thrift)" /><br />
<em>Architecture IoT/BigData – Storing WIFI traffic in Apache Cassandra (WSO2 BAM and Apache Thrift)</em></p>
<p><!-- more --></p>
<h2>I.- Looking for the Streaming and/or Communication Protocol</h2>
<p>There are some stream and communication protocols and implementations</p>
<p>Really, there are many libraries and streaming protocols out there to solve the above issues, but if you are looking for a protocol/library open source, lightweight, low memory footprint and developer friendly there are a few. They are:</p>
<p><strong>1) Elastic Logstash (https://www.elastic.co/products/logstash)</strong></p>
<p>Logstash is a set of tools to collect heterogeneous type of data and It's to used with Elasticsearch, It requires Java and for this reason It is too heavy to run in a Raspberry Pi. The best choice is to use only <code>Logstash Forwarder</code>.<br />
<a href="https://github.com/elastic/logstash-forwarder"><code>Logstash Forwarder</code> (a.k.a. <code>lumberjack</code>)</a> is the protocol used to ship, parse and collect streams or log-events when using ELK.<br />
<code>Logstash Forwarder</code> can be downloaded and compiled using the Go compiler on your Raspberry Pi, <a href="http://michaelblouin.ca/blog/2015/06/08/build-run-logstash-forwarder-rasperry-pi">for further information you can use this link</a>.</p>
<p><strong>2) Elastic Filebeat (https://github.com/elastic/beats/tree/master/filebeat)</strong></p>
<blockquote><p>
  Filebeat is a lightweight, open source shipper for log file data. As the next-generation <a href="https://github.com/elastic/logstash-forwarder"><code>Logstash Forwarder</code></a>, Filebeat tails logs and<br />
  quickly sends this information to Logstash for further parsing and enrichment or to Elasticsearch for centralized storage and analysis.
</p></blockquote>
<p>Installing and configuring <code>Filebeat</code> is easy and you can use It with Logstash to perform additional processing on the data collected and the <code>Filebeat</code> replaces <code>Logstash Forwarder</code>.</p>
<p><strong>3) Apache Flume (https://flume.apache.org)</strong></p>
<blockquote><p>
  Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of<br />
  log data. It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable<br />
  reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online<br />
  analytic application.
</p></blockquote>
<p><code>Apache Flume</code> used Java and requires high (memory and CPU) resources.</p>
<p><strong>4) Mozilla Heka (https://github.com/mozilla-services/heka)</strong></p>
<blockquote><p>
  Heka is an open source stream processing software system developed by Mozilla. Heka is a “Swiss Army Knife” type tool for data<br />
  processing, useful for a wide variety of different tasks, such as:</p>
<ul>
<li>Loading and parsing log files from a file system.</li>
<li>Accepting statsd type metrics data for aggregation and forwarding to upstream time series data stores such as graphite or InfluxDB.</li>
<li>Launching external processes to gather operational data from the local system.</li>
<li>Performing real time analysis, graphing, and anomaly detection on any data flowing through the Heka pipeline.</li>
<li>Shipping data from one location to another via the use of an external transport (such as AMQP) or directly (via TCP).</li>
<li>Delivering processed data to one or more persistent data stores.</li>
</ul>
</blockquote>
<p><code>Mozilla Heka</code> is very similar to <code>Logstash Forwarder</code>, both are written in Go, but <code>Mozilla Heka</code> can process the log-events in real-time also Heka is also able to provide graphs of this data directly, those are great advantages. These graphs will be updated in real time, as the data is flowing through Heka, without the latency of the data store driven graphs.</p>
<p><strong>5) Fluentd (https://github.com/fluent/fluentd)</strong></p>
<blockquote><p>
  Fluentd is similar to Logstash in that there are inputs and outputs for a large variety of sources and destination. Some of it’s design tenets<br />
  are easy installation and small footprint. It doesn’t provide any storage tier itself but allows you to easily configure where your logs should<br />
  be collected.
</p></blockquote>
<p><strong>6) Apache Thrift (https://thrift.apache.org)</strong></p>
<blockquote><p>
  Thrift is an interface definition language and binary communication protocol[1] that is used to define and create services for numerous languages.<br />
  It is used as a remote procedure call (RPC) framework and was developed at Facebook for "scalable cross-language services development". It<br />
  combines a software stack with a code generation engine to build services that work efficiently to a varying degree and seamlessly between C#,<br />
  C++ (on POSIX-compliant systems), Cappuccino, Cocoa, Delphi, Erlang, Go, Haskell, Java, Node.js, OCaml, Perl, PHP, Python, Ruby and Smalltalk.<br />
  Although developed at Facebook, it is now an open source project in the Apache Software Foundation.
</p></blockquote>
<p><a href="https://github.com/facebookarchive/scribe"><code>Facebook Scribe</code></a> is a project what uses the <code>Thrift</code> protocol and is a server for aggregating log data streamed in real time from a large number of servers.</p>
<p>In this Proof-of-Concept I will use Apache Thrift for these reasons:</p>
<ul>
<li>Apache Thrift is embedded in WSO2 BAM 2.5.0.</li>
<li>The WSO2 BAM 2.5.0 is a very important component because also It embeds Apache Cassandra to persist the data stream/log-events. You don't need to do anything, all log-events captured will be stored automatically in Apache Cassandra.</li>
<li>There are lightweight Python libraries implementing the Apache Thrift protocol, this <a href="https://github.com/wso2-incubator/iot-server-appliances/tree/master/Arduino%20Robot/PC_Clients/PythonRobotController/DirectPublishClient/BAMPythonPublisher">Thrift Python Client</a> is suitable to be used in a Raspberry Pi and publish events int WSO2 BAM (Apache Cassandra).</li>
<li>And finally, there is a <a href="https://github.com/PaulMcMillan/kismetclient">Python Client Library specific for Kismet</a>. This Python Kismet Client reads the traffic captured for Kismet.</li>
</ul>
<h2>II.- Installing, configuring and running Python Kismet Client and Python Thrift library</h2>
<p>I cloned the above repositories (<a href="https://github.com/chilcano/iot-server-appliances/tree/master/Arduino%20Robot/PC_Clients/PythonRobotController/DirectPublishClient/BAMPythonPublisher">Thrift Python Client</a> and <a href="https://github.com/chilcano/kismetclient">Python Kismet Client</a>).</p>
<p>[code lang=bash]<br />
$ mkdir kismet_to_wso2bam<br />
$ cd kismet_to_wso2bam</p>
<p>// Install svn client, It&#039;s useful to download a folder from a Github repo<br />
$ sudo apt-get install subversion<br />
[/code]</p>
<p>Replace <code>tree/master</code> for <code>trunk</code> in the URL and checkout the folder.</p>
<p>[code lang=bash]<br />
// List files and subfolders<br />
$ svn ls https://github.com/chilcano/iot-server-appliances/trunk/Arduino%20Robot/PC_Clients/PythonRobotController/DirectPublishClient/BAMPythonPublisher<br />
.gitignore<br />
BAMPublisher.py<br />
Publisher.py<br />
PythonClient.py<br />
README.md<br />
gen-py/<br />
thrift/</p>
<p>// Download files and subfolder<br />
$ svn checkout https://github.com/chilcano/iot-server-appliances/trunk/Arduino%20Robot/PC_Clients/PythonRobotController/DirectPublishClient/BAMPythonPublisher<br />
[/code]</p>
<p>Now, download the <code>kismetclient</code> repository.</p>
<p>[code lang=bash]<br />
$ git clone https://github.com/chilcano/kismetclient<br />
Cloning into &#039;kismetclient&#039;...<br />
remote: Counting objects: 100, done.<br />
remote: Total 100 (delta 0), reused 0 (delta 0), pack-reused 100<br />
Receiving objects: 100% (100/100), 15.84 KiB, done.<br />
Resolving deltas: 100% (57/57), done.<br />
[/code]</p>
<p><strong>2.1) Creating a custom Python script to send the Kismet captured traffic to WSO2 BAM 2.5.0</strong></p>
<p>Under <code>kismet_to_wso2bam</code> folder create this Python (<a href="https://github.com/chilcano/wso2bam-wifi-thrift-cassandra-poc/tree/master/raspberrypi_wifi_traffic_capture/sendTrafficFromKismetToWSO2BAM.py">sendTrafficFromKismetToWSO2BAM.py</a>) script.</p>
<p>[code lang=python]<br />
#!/usr/bin/env python<br />
&quot;&quot;&quot;<br />
Python script to send 802.11 traffic captured for Kismet to WSO2 BAM 2.5.0.</p>
<p>Author:  Chilcano<br />
Date:    2015/12/31<br />
Version: 1.0</p>
<p>Requires:<br />
- Python Thrift Client (https://github.com/chilcano/iot-server-appliances/tree/master/Arduino%20Robot/PC_Clients/PythonRobotController/DirectPublishClient/BAMPythonPublisher)<br />
- Python Kismet Client (https://github.com/chilcano/kismetclient)<br />
- Place the &#039;sendTrafficFromKismetToWSO2BAM.py&#039; in same level of &#039;BAMPythonPublisher&#039; and &#039;kismetclient&#039; folders.</p>
<p>Run:<br />
$ python sendTrafficFromKismetToWSO2BAM.py<br />
&quot;&quot;&quot;</p>
<p>import sys<br />
sys.path.append(&#039;kismetclient&#039;)<br />
sys.path.append(&#039;BAMPythonPublisher&#039;)<br />
sys.path.append(&#039;BAMPythonPublisher/gen-py&#039;)<br />
sys.path.append(&#039;BAMPythonPublisher/thrift&#039;)</p>
<p>from kismetclient import Client as KismetClient<br />
from kismetclient import handlers<br />
from Publisher import *<br />
from pprint import pprint</p>
<p>import logging<br />
import time</p>
<p>log = logging.getLogger(&#039;kismetclient&#039;)<br />
log.addHandler(logging.StreamHandler())<br />
log.setLevel(logging.DEBUG)</p>
<p># Kismet server<br />
address = (&#039;127.0.0.1&#039;, 2501)<br />
k = KismetClient(address)<br />
##k.register_handler(&#039;TRACKINFO&#039;, handlers.print_fields)</p>
<p># BAM/CEP/Thrift Server<br />
cep_ip = &#039;192.168.1.43&#039; # IP address of the server<br />
cep_port = 7713         # Thrift listen port of the server<br />
cep_username = &#039;admin&#039;  # username<br />
cep_password = &#039;admin&#039;  # passowrd</p>
<p># Initialize publisher with ip and port of server<br />
publisher = Publisher()<br />
publisher.init(cep_ip, cep_port)</p>
<p># Connect to server with username and password<br />
publisher.connect(cep_username, cep_password)</p>
<p># Define the Input Stream<br />
streamDefinition = &quot;{ &#039;name&#039;:&#039;rpi_kismet_stream_in&#039;, &#039;version&#039;:&#039;1.0.0&#039;, &#039;nickName&#039;: &#039;rpi_k_in&#039;, &#039;description&#039;: &#039;802.11 passive packet capture&#039;, &#039;tags&#039;: [&#039;RPi 2 Model B&#039;, &#039;Kismet&#039;, &#039;Thrift&#039;], &#039;metaData&#039;:[ {&#039;name&#039;:&#039;ipAdd&#039;,&#039;type&#039;:&#039;STRING&#039;},{&#039;name&#039;:&#039;deviceType&#039;,&#039;type&#039;:&#039;STRING&#039;},{&#039;name&#039;:&#039;owner&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;bssid&#039;,&#039;type&#039;:&#039;STRING&#039;}], &#039;payloadData&#039;:[ {&#039;name&#039;:&#039;macAddress&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;type&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;llcpackets&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;datapackets&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;cryptpackets&#039;,&#039;type&#039;:&#039;STRING&#039;},{&#039;name&#039;:&#039;signal_dbm&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;bestlat&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;bestlon&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;bestalt&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;channel&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;datasize&#039;,&#039;type&#039;:&#039;STRING&#039;}, {&#039;name&#039;:&#039;newpackets&#039;,&#039;type&#039;:&#039;STRING&#039;}] }&quot;;<br />
publisher.defineStream(streamDefinition)</p>
<p>def handle_client(client, bssid, mac, lasttime, type, llcpackets, datapackets, cryptpackets, signal_dbm, bestlat, bestlon, bestalt, channel, datasize, newpackets):<br />
  publisher.publish([&#039;rpi_chicha&#039;, &#039;RPi 2 Model B&#039;, &#039;chilcano.io&#039;, int(lasttime)], [bssid, mac, type, llcpackets, datapackets, cryptpackets, signal_dbm, bestlat, bestlon, bestalt, channel, datasize, newpackets])</p>
<p>k.register_handler(&#039;CLIENT&#039;, handle_client)</p>
<p>try:<br />
    while True:<br />
        k.listen()<br />
except KeyboardInterrupt:<br />
    pprint(k.protocols)<br />
    publisher.disconnect()<br />
    log.info(&#039;Exiting...&#039;)</p>
<p>[/code]</p>
<p>At the end, the structure of files and directories will be as shown below:</p>
<p>[code lang=bash]<br />
$ ll<br />
total 20<br />
drwxr-xr-x  4 pi pi 4096 Feb  3 14:39 ./<br />
drwxr-xr-x 11 pi pi 4096 Feb  3 12:10 ../<br />
drwxr-xr-x  5 pi pi 4096 Feb  3 12:14 BAMPythonPublisher/<br />
drwxr-xr-x  4 pi pi 4096 Feb  3 12:11 kismetclient/<br />
-rw-r--r--  1 pi pi 2552 Feb  3 12:14 sendTrafficFromKismetToWSO2BAM.py</p>
<p>$ tree -L 3<br />
.<br />
├── BAMPythonPublisher<br />
│   ├── BAMPublisher.py<br />
│   ├── gen-py<br />
│   │   ├── Data<br />
│   │   ├── Exception<br />
│   │   ├── __init__.py<br />
│   │   ├── ThriftEventTransmissionService<br />
│   │   └── ThriftSecureEventTransmissionService<br />
│   ├── Publisher.py<br />
│   ├── Publisher.pyc<br />
│   ├── PythonClient.py<br />
│   ├── README.md<br />
│   └── thrift<br />
│       ├── __init__.py<br />
│       ├── __init__.pyc<br />
│       ├── protocol<br />
│       ├── server<br />
│       ├── Thrift.py<br />
│       ├── Thrift.pyc<br />
│       ├── transport<br />
│       ├── TSCons.py<br />
│       ├── TSerialization.py<br />
│       └── TTornado.py<br />
├── kismetclient<br />
│   ├── kismetclient<br />
│   │   ├── client.py<br />
│   │   ├── client.pyc<br />
│   │   ├── exceptions.py<br />
│   │   ├── exceptions.pyc<br />
│   │   ├── handlers.py<br />
│   │   ├── handlers.pyc<br />
│   │   ├── __init__.py<br />
│   │   ├── __init__.pyc<br />
│   │   ├── utils.py<br />
│   │   └── utils.pyc<br />
│   ├── LICENSE<br />
│   ├── README.md<br />
│   ├── runclient.py<br />
│   └── setup.py<br />
└── sendTrafficFromKismetToWSO2BAM.py</p>
<p>12 directories, 28 files<br />
[/code]</p>
<p>Notes:</p>
<ul>
<li>You have to update the <code>sendTrafficFromKismetToWSO2BAM.py</code> with IP Address, Username, Password and Ports where WSO2 BAM is running.</li>
<li>The above Python script reads the captured traffic and defines previously a structure of data to be send to WSO2 BAM (Apache Thrift). You can modify that data structure by adding or removing 802.11 fields.</li>
</ul>
<p><strong>2.2) Install and configure WSO2 BAM to receive the Kismet traffic</strong></p>
<p>Before you run the <code>sendTrafficFromKismetToWSO2BAM.py</code>, WSO2 BAM 2.5.0 should be running and the Thrift listener port should be open.<br />
The Thrift listener standard port is <code>7711</code>, in my case I have an offset of  <code>+2</code>.</p>
<p>I recommend you <a href="https://hub.docker.com/r/chilcano/wso2-bam/">my Docker container created to get a fully functional WSO2 BAM 2.5.0</a> ready for use in this PoC with Kismet.<br />
To do that, open a new terminal in your Host PC and execute the next commands:</p>
<p>Initialize the Docker environment.</p>
<p>[code lang=bash]<br />
$ docker-machine ls</p>
<p>$ docker-machine start default</p>
<p>$ eval &quot;$(docker-machine env default)&quot;</p>
<p>$ docker login<br />
[/code]</p>
<p>Download the WSO2 BAM Docker image from Docker Hub.</p>
<p>[code lang=bash]<br />
$ docker pull chilcano/wso2-bam:2.5.0</p>
<p>2.5.0: Pulling from chilcano/wso2-bam<br />
9acb471e45a5: Pull complete<br />
...<br />
e12995f4907c: Pull complete<br />
77e4386b8b45: Pull complete<br />
Digest: sha256:64e40ea4ea6b89c7e1b08edeb43e31467196a11c9fe755c0026403780f9e24e1<br />
Status: Downloaded newer image for chilcano/wso2-bam:2.5.0</p>
<p>$ docker images<br />
REPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE<br />
chilcano/netcat         jessie              302d06d998e6        5 days ago          135.1 MB<br />
chilcano/rtail-server   latest              cb313f9e2546        7 days ago          674.2 MB<br />
ubuntu                  wily                d8a164f81acc        7 days ago          134.4 MB<br />
ubuntu                  vivid               99639e3e70c8        7 days ago          131.3 MB<br />
debian                  jessie              7a01cc5f27b1        8 days ago          125.1 MB<br />
node                    0.12.9              d09c6f7639f7        13 days ago         637.1 MB<br />
ubuntu                  trusty              6cc0fc2a5ee3        2 weeks ago         187.9 MB<br />
ubuntu                  precise             6b4adea2c00e        2 weeks ago         137.5 MB<br />
sebp/elk                latest              96f071b7a8e2        3 weeks ago         980.8 MB<br />
chilcano/wso2-bam       2.5.0               77e4386b8b45        7 weeks ago         1.65 GB<br />
chilcano/wso2-dss       3.2.1               acd92f55f678        7 weeks ago         1.383 GB<br />
chilcano/wiremock       latest              a3e4764483b9        7 weeks ago         597.3 MB<br />
java                    openjdk-7           e93dd201a77e        8 weeks ago         589.7 MB</p>
<p>$ docker run -d -t --name=wso2bam-kismet -p 9445:9443 -p 7713:7711 chilcano/wso2-bam:2.5.0<br />
fc9fb8368e7f4f24b01bc33f90122776b4c10d63d0e849073474a485700b6266</p>
<p>$ docker ps<br />
CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                                                                                     NAMES<br />
fc9fb8368e7f        chilcano/wso2-bam:2.5.0   &quot;/bin/sh -c &#039;sh ./wso&quot;   9 seconds ago       Up 8 seconds        7611/tcp, 9160/tcp, 9763/tcp, 21000/tcp, 0.0.0.0:7713-&gt;7711/tcp, 0.0.0.0:9445-&gt;9443/tcp   wso2bam-kismet<br />
[/code]</p>
<p>The <code>9445</code> port is for the WSO2 Carbon Admin Console and the <code>7713</code> port is the Thrift listener port.<br />
Now, let's verify that WSO2 BAM is running in the Docker container.</p>
<p>[code lang=bash]<br />
$ docker exec -ti wso2bam-kismet bash</p>
<p>root@fc9fb8368e7f:/opt/wso2bam02a/bin# tail -f ../repository/logs/wso2carbon.log<br />
TID: [0] [BAM] [2016-02-03 16:38:10,482]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}<br />
TID: [0] [BAM] [2016-02-03 16:38:10,664]  INFO {org.apache.cassandra.net.OutboundTcpConnection} -  Handshaking version with localhost/127.0.0.1 {org.apache.cassandra.net.OutboundTcpConnection}<br />
TID: [0] [BAM] [2016-02-03 16:38:10,672]  INFO {org.apache.cassandra.net.OutboundTcpConnection} -  Handshaking version with localhost/127.0.0.1 {org.apache.cassandra.net.OutboundTcpConnection}<br />
TID: [0] [BAM] [2016-02-03 16:38:11,127]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][BAM_NOTIFICATION_DISPATCHER_TASK][NOTIFIER] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}<br />
TID: [0] [BAM] [2016-02-03 16:38:11,232]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11111/jndi/rmi://localhost:9999/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}<br />
TID: [0] [BAM] [2016-02-03 16:38:11,246]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2BAM02A-2.5.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}<br />
TID: [0] [BAM] [2016-02-03 16:38:11,247]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 41 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}<br />
TID: [0] [BAM] [2016-02-03 16:38:14,044]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}<br />
TID: [0] [BAM] [2016-02-03 16:38:14,714]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://172.17.0.2:9443/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}<br />
TID: [0] [BAM] [2016-02-03 16:38:14,714]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://172.17.0.2:9763/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}<br />
[/code]</p>
<p><strong>2.3) Remote access of different network (i.e. Raspberry Pi) to the WSO2 BAM Docker container</strong></p>
<p>If you want to get access to WSO2 BAM from a web browser, to use this URL <code>https://192.168.99.100:9445/carbon/admin</code>, but if you want to connect to embedded Thrift listener, to use this IP Address <code>192.168.99.100</code> and this <code>7713</code> port.<br />
That is valid if you are in the same Host PC, but how to get access remotely, for example from the above Raspberry Pi, to the WSO2 BAM Docker Container?.<br />
To do that, follow this explanation (<a href="https://sheerun.net/2014/05/17/remote-access-to-docker-with-tls/">Remote access to Docker with TLS</a>), as It is mentioned, there are 3 choices, as I'm running Docker deamon in a Mac OS X, the easy way to expose and to do available the Docker container to Raspberry Pi network is to do <code>port forwarding</code> or <code>SSH tunneling</code> using <code>docker-machine</code>.</p>
<p>In other words, follow these commands in your Host PC (Mac OS X):</p>
<p>[code lang=bash]<br />
$ docker -v<br />
Docker version 1.9.1, build a34a1d5<br />
[/code]</p>
<p>As WSO2 BAM opens <code>9445</code> and <code>7713</code> ports, then I will open/forward both ports.</p>
<p>[code lang=bash]<br />
$ docker-machine ssh default -f -N -L 192.168.1.43:7713:localhost:7713</p>
<p>// Optional<br />
$ docker-machine ssh default -f -N -L 192.168.1.43:9445:localhost:9445<br />
[/code]</p>
<p>Where:</p>
<ul>
<li><code>'-f'</code> requests SSH to go to background just before command execution.</li>
<li><code>'-N'</code> allows empty command (useful here to forward ports only).</li>
<li>The user/password for <code>boot2docker</code> is <code>docker/tcuser</code>.</li>
</ul>
<p>You also can do the same but using the <code>ssh</code> command:</p>
<p>[code lang=bash]<br />
$ ssh docker@$(docker-machine ip default) -f -N -L 192.168.1.43:7713:localhost:7713<br />
[/code]</p>
<p>Now, from the Raspberry Pi, check if WSO2 BAM is reachable.</p>
<p>[code lang=bash]<br />
$ nc -vzw 3 192.168.1.43 7713<br />
Connection to 192.168.1.43 7713 port [tcp/*] succeeded!</p>
<p>// Optional<br />
$ nc -vzw 3 192.168.1.43 9445<br />
Connection to 192.168.1.43 9445 port [tcp/*] succeeded!<br />
[/code]</p>
<p>Or check It by using <code>curl</code>.</p>
<p>[code lang=bash]<br />
$ curl -Ivsk https://192.168.1.43:9445/carbon/admin/login.jsp -o /dev/null</p>
<p>...<br />
&lt; HTTP/1.1 200 OK<br />
&lt; Set-Cookie: JSESSIONID=601A0F02DCCB47B2685686A7042BBD8F; Path=/; Secure; HttpOnly<br />
&lt; X-FRAME-OPTIONS: DENY<br />
&lt; Content-Type: text/html;charset=UTF-8<br />
&lt; Content-Language: en<br />
&lt; Transfer-Encoding: chunked<br />
&lt; Vary: Accept-Encoding<br />
&lt; Date: Thu, 04 Feb 2016 12:14:09 GMT<br />
&lt; Server: WSO2 Carbon Server<br />
&lt;<br />
* Connection #0 to host 192.168.1.43 left intact<br />
* Closing connection #0<br />
* SSLv3, TLS alert, Client hello (1):<br />
} [data not shown]<br />
[/code]</p>
<p><strong>2.4) Running the custom Python script to send the captured traffic by Kismet to WSO2 BAM</strong></p>
<p>Make sure that Python is installed, install It if It's not installed.</p>
<p>[code lang=bash]<br />
$ python<br />
Python 2.7.3 (default, Mar 18 2014, 05:13:23)<br />
[GCC 4.6.3] on linux2<br />
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.<br />
&gt;&gt;&gt; quit()<br />
[/code]</p>
<p>After that, run the Python script, obviously, Kismet should be running.</p>
<p>[code lang=bash]<br />
$ cd kismet_to_wso2bam/</p>
<p>$ python sendTrafficFromKismetToWSO2BAM.py</p>
<p>*KISMET: [&#039;0.0.0&#039;, &#039;1454495618&#039;, &#039;rpi-chicha&#039;, &#039;pcapdump,netxml,nettxt,gpsxml,alert&#039;, &#039;1000&#039;]<br />
Server: 0.0.0 1454495618 rpi-chicha pcapdump,netxml,nettxt,gpsxml,alert 1000<br />
*PROTOCOLS: [&#039;KISMET,ERROR,ACK,PROTOCOLS,CAPABILITY,TERMINATE,TIME,PACKET,STATUS,PLUGIN,SOURCE,ALERT,COMMON,TRACKINFO,WEPKEY,STRING,GPS,BSSID,SSID,CLIENT,BSSIDSRC,CLISRC,NETTAG,CLITAG,REMOVE,CHANNEL,INFO,BATTERY,CRITFAIL&#039;]<br />
!1 CAPABILITY KISMET<br />
!2 CAPABILITY ERROR<br />
!3 CAPABILITY ACK<br />
...<br />
[/code]</p>
<p>In the WSO2 BAM side you will see the below log events where Raspberry Pi (Kismet) is connecting to WSO2 BAM (Thrift listener) successfully.</p>
<p>[code lang=bash]<br />
...<br />
TID: [0] [BAM] [2016-02-04 12:27:40,542]  INFO {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil} -  &#039;admin@carbon.super [-1234]&#039; logged in at [2016-02-04 12:27:40,542+0000] {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil}<br />
TID: [0] [BAM] [2016-02-04 12:29:20,334]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  user admin connected {org.wso2.carbon.databridge.core.DataBridge}<br />
TID: [0] [BAM] [2016-02-04 12:29:20,416]  INFO {org.wso2.carbon.databridge.streamdefn.registry.datastore.RegistryStreamDefinitionStore} -  Stream definition added to registry successfully : rpi_kismet_stream_in:1.0.0 {org.wso2.carbon.databridge.streamdefn.registry.datastore.RegistryStreamDefinitionStore}<br />
TID: [0] [BAM] [2016-02-04 12:29:20,670]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory} -  Initializing Event cluster {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory}<br />
TID: [0] [BAM] [2016-02-04 12:29:20,877]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory} -  Initializing Event Index cluster {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory}<br />
[/code]</p>
<h2>III.- Exploring the 802.11 captured traffic stored in Apache Cassandra (WSO2 BAM)</h2>
<p>Remember, the WSO2 BAM 2.5.0 Docker Container is running locally with a internal Docker Machine IP Address (<code>192.168.99.100</code>), also is running with a public IP Address by using the Host IP Address (<code>192.168.1.43</code>) because the internal IP address was forwarded.<br />
In brief, WSO2 BAM has the below addresses:</p>
<ul>
<li>From the Internal Docker Machine IP address:
<ul>
<li>WSO2 BAM Admin Web Console: https://192.168.99.100:9445/carbon/admin</li>
<li>Thrift listener: tcp://192.168.99.100:7713</li>
</ul>
</li>
<li>From the Public IP address:
<ul>
<li>WSO2 BAM Admin Web Console: https://192.168.1.43:9445/carbon/admin</li>
<li>Thrift listener: tcp://192.168.1.43:7713</li>
</ul>
</li>
</ul>
<p>Then, let's go to explore the 802.11 traffic stored in Apache Cassandra.<br />
Below a set of images took when browsing the Apache Cassandra embedded in WSO2 BAM.</p>
<p><em>01 / WSO2 BAM / Apache Cassandra - Key Spaces</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-2-wso2bam-cassandra-keyspaces.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>02 / WSO2 BAM / Apache Cassandra - Event KS information</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-3-wso2bam-event-ks-info.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>03 / WSO2 BAM / Apache Cassandra - Event KS information</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-4-event-ks-info.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>04 / WSO2 BAM / Apache Cassandra - Connecting to explore KS</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-5-connect-cassandra.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>05 / WSO2 BAM / Apache Cassandra - List of Key Spaces</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-6-list-keyspaces.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>06 / WSO2 BAM / Apache Cassandra - Exploring the Kismet data</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-7-kismet-data.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p><em>07 / WSO2 BAM / Apache Cassandra - Exploring the Kismet data</em><br />
<img src="{{ site.baseurl }}/assets/chilcano-02-raspberrypi-bigdata-wifi-thrift-8-kismet-data.png" alt="WSO2 BAM / Apache Cassandra 01" title="WSO2 BAM / Apache Cassandra 01" /></p>
<p>In the blog post (Part III), I will explain how to create a simple Dashboard showing the WIFI traffic captured in real-time.<br />
See you soon.</p>
