<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-03-30T15:42:53+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Holistic Security</title><subtitle>Systems Thinking, Holism, Trust, Security &amp; Usability.</subtitle><entry><title type="html">Github Pages and Jekyll on Windows 10</title><link href="http://localhost:4000/2020/03/30/github-pages-and-jekyll-on-windows-10" rel="alternate" type="text/html" title="Github Pages and Jekyll on Windows 10" /><published>2020-03-30T01:10:00+02:00</published><updated>2020-03-30T01:10:00+02:00</updated><id>http://localhost:4000/2020/03/30/github-pages-and-jekyll-on-windows-10</id><content type="html" xml:base="http://localhost:4000/2020/03/30/github-pages-and-jekyll-on-windows-10">I have an older Surface 3 Pro (4GB RAM, 64GB SSD, Windows 10) and want to publish new posts in my existing Jekyll static Blog hosted on Github Pages which I created it from other Laptop with Ubuntu. To do that I have to configure the Surface 3 Pro. Then, I'm going to follow the [Jekyll on Windows](https://jekyllrb.com/docs/installation/windows) guide. Then I'll download and install a Ruby+Devkit version from [RubyInstaller Downloads](https://rubyinstaller.org/downloads). 

[![](/assets/blog20200330/20200330-github-pages-and-jekyll-on-windows-10-1.png){:width=&quot;400&quot;}{:style=&quot;display:block;margin:auto;&quot;}](/assets/blog20200330/20200330-github-pages-and-jekyll-on-windows-10-1.png.png)

&lt;!-- more --&gt;

Once finished, open a CMD as standard user and check the installed version:

```sh
C:\Users\rmce&gt; ruby --version
ruby 2.6.5p114 (2019-10-01 revision 67812) [x64-mingw32]
```
 
Download existing the Github Pages site:

```sh
C:\Users\rmce&gt; y:
Y:\&gt; cd __gitrepos
Y:\__gitrepos&gt; git clone https://github.com/chilcano/ghpages-holosec
Y:\__gitrepos&gt; cd ghpages-holosec
```

Install Bundler:

```sh
Y:\__gitrepos\ghpages-holosec&gt; gem install bundler
Y:\__gitrepos\ghpages-holosec&gt; bundle config set path 'vendor/bundle'
```

Install Jekyll and all Gems via Bundler:

```sh
Y:\__gitrepos\ghpages-holosec&gt; bundle 
```

Check if Jekyll was installed properly:

```sh
Y:\__gitrepos\ghpages-holosec&gt; bundle exec jekyll -v
jekyll 4.0.0
```

Now we are ready to serve the site in our computer:

```sh
Y:\__gitrepos\ghpages-holosec&gt; bundle exec jekyll serve
```

If you are using Google Analytics plugin configured, you can try this:

```sh
Y:\__gitrepos\ghpages-holosec&gt; set JEKYLL_ENV=production 
Y:\__gitrepos\ghpages-holosec&gt; bundle exec jekyll serve --incremental --watch 
Configuration file: Y:/__gitrepos/ghpages-holosec/_config.yml
            Source: Y:/__gitrepos/ghpages-holosec
       Destination: Y:/__gitrepos/ghpages-holosec/_site
 Incremental build: enabled
      Generating...
       Jekyll Feed: Generating feed for posts
                    done in 192.797 seconds.
 Auto-regeneration: enabled for 'Y:/__gitrepos/ghpages-holosec'
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.
```

[![](/assets/blog20200330/20200330-github-pages-and-jekyll-on-windows-10-2.png){:width=&quot;400&quot;}{:style=&quot;display:block;margin:auto;&quot;}](/assets/blog20200330/20200330-github-pages-and-jekyll-on-windows-10-2.png.png)</content><author><name></name></author><category term="github" /><category term="jekyll" /><category term="ruby" /><summary type="html">I have an older Surface 3 Pro (4GB RAM, 64GB SSD, Windows 10) and want to publish new posts in my existing Jekyll static Blog hosted on Github Pages which I created it from other Laptop with Ubuntu. To do that I have to configure the Surface 3 Pro. Then, I’m going to follow the Jekyll on Windows guide. Then I’ll download and install a Ruby+Devkit version from RubyInstaller Downloads.</summary></entry><entry><title type="html">Minimum Viable Security for a Kubernetised Webapp: HTTP Basic Auth on TLS - Part2</title><link href="http://localhost:4000/2020/03/19/minimum-viable-security-for-a-k8s-webapp-http-basic-auth-on-tls-part2" rel="alternate" type="text/html" title="Minimum Viable Security for a Kubernetised Webapp: HTTP Basic Auth on TLS - Part2" /><published>2020-03-19T00:10:00+01:00</published><updated>2020-03-19T00:10:00+01:00</updated><id>http://localhost:4000/2020/03/19/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part2</id><content type="html" xml:base="http://localhost:4000/2020/03/19/minimum-viable-security-for-a-k8s-webapp-http-basic-auth-on-tls-part2">In the &quot;[Minimum Viable Security for a Kubernetised Webapp: TLS everywhere - Part1](/2020/03/08/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part1)&quot; I used the [Affordable K8s](https://github.com/chilcano/affordable-k8s)' Terraform scripts to create a K8s Cluster with the Jetstack Cert-Manager and the NGINX Ingress Controller pre-installed, now I want to improve the security of a Webapp hosted in that Cluster according the __Minimum Viable Security__ (MVSec) and __Pareto Principle or 80/20 rule__. 

[![](/assets/blog20200319/mvp-sec-part2-http-basic-auth-over-tls-for-weave-scope-with-nginx-ingress-jetstack-cert-manager-lets-encrypt.png){:width=&quot;400&quot;}{:style=&quot;display:block;margin:auto;&quot;}](/assets/blog20200319/mvp-sec-part2-http-basic-auth-over-tls-for-weave-scope-with-nginx-ingress-jetstack-cert-manager-lets-encrypt.png)


In this post I'll explain how to enable and configure _[HTTP Basic Authentication](https://en.wikipedia.org/wiki/Basic_access_authentication) over TLS_ in the [Weave Scope](https://www.weave.works/oss/scope) webapp running in the recently created K8s Cluster. 

&lt;!-- more --&gt; 

I recommend follow the [Part 1](/2020/03/08/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part1) to get this scenario.
Let's explore the K8s services created.
```sh
$ kubectl get svc -n weave
```
- The `weave-scope-app-svc-np` NodePort service will create the `weave-scope.cloud.holisticsecurity.io` subdomain entry in AWS Route 53.
- The `weave-scope-app-svc-np` NodePort service is required when I'm getting access through SSH tunnel.
- The `weave-scope-app` ClusterIP service was created when Weave Scope was installed.


Get access through SSH to your K8s Cluster and clone the [Affordable K8s](https://github.com/chilcano/affordable-k8s) Git Repo. It contains all YAML files required for next steps.

```sh 
$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem

$ git clone https://github.com/chilcano/affordable-k8s
$ cd affordable-k8s/examples/
```

Since I'll use HTTP Basic Auth, I need creating a K8s secret resources that the NGINX Ingress resources for Weave Scope will need. 
```sh
$ sudo apt install apache2-utils -y
$ htpasswd -bc auth YOUR_USR YOUR_PWD
$ kubectl create secret generic secret-http-basic-auth --from-file=auth -n weave
```

### Enabling and configuring HTTP Basic Authentication over TLS


**1. Create a Let’s Encrypt Issuer**

A Certificate issuer is the definition for where [Jetstack Cert-Manager](https://cert-manager.io/docs/concepts/issuer/#namespaces) will get request TLS certs. An `Issuer` is specific to a single namespace in Kubernetes, and a `ClusterIssuer` is meant to be a cluster-wide definition for the same purpose. 

In a scenario or project real, we should generate certificates for testing (`staging`) purporses, once tested the process to get and configure testing certificates, the next step is to get and use final (`production`) certificates. That is the reason I provide `letsencrypt-issuer-staging.yaml` and `letsencrypt-issuer-prod.yaml`. Then, let's create both issuers.

```sh
$ kubectl apply -f letsencrypt-issuer-staging.yaml -n weave
$ kubectl apply -f letsencrypt-issuer-prod.yaml -n weave
```

Checking the Let's Encrypt Issuers. If you got `&quot;Reason: ACMEAccountRegistered&quot;`, the Issuer is ready to issue certificates.
```sh
$ kubectl get issuer,secret -n weave
NAME                                                READY   AGE
issuer.cert-manager.io/letsencrypt-issuer-prod      True    14s
issuer.cert-manager.io/letsencrypt-issuer-staging   True    76s

NAME                                        TYPE                                  DATA   AGE
secret/default-token-gzbzs                  kubernetes.io/service-account-token   3      7m30s
secret/letsencrypt-issuer-privkey-prod      Opaque                                1      12s
secret/letsencrypt-issuer-privkey-staging   Opaque                                1      74s
secret/secret-http-basic-auth               Opaque                                1      3m6s
secret/weave-scope-token-vb7vg              kubernetes.io/service-account-token   3      7m31s


$ kubectl describe issuer letsencrypt-issuer-staging -n weave
$ kubectl describe issuer letsencrypt-issuer-prod -n weave
```

If you have under `Status` this `Reason: ACMEAccountRegistered` message in both issuers, that means they are ready to get certificates from Let's Encrypt.


**2. Create the Ingress resource with a Staging Certificate**

```sh
$ kubectl apply -f weave-scope-app-ingress.yaml 
```

With `weave-scope-app-ingress.yaml` I'll have a testing certificate.
```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: weave-scope-app-ingress
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    cert-manager.io/issuer: &quot;letsencrypt-issuer-staging&quot;
    #cert-manager.io/issuer: &quot;letsencrypt-issuer-prod&quot;
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: secret-http-basic-auth
  namespace: weave
spec:
  rules:
  - host: weave-scope.cloud.holisticsecurity.io
    http:
      paths:
      - path: /
        backend:
          serviceName: weave-scope-app-svc-np  ## NodePort
          servicePort: 82
  tls:
  - hosts:
    - weave-scope.cloud.holisticsecurity.io
    secretName: cert-tls
```

When creating the TLS NGINX Ingress resources, the NGINX Ingress Controller underhood will execute the next steps:
- Request a TLS Cert through the Let's Encrypt Issuer (`letsencrypt-issuer-staging`).
- Load the issued TLS Cert and its configuration to route the `weave-scope.cloud.holisticsecurity.io` incomming traffic over TLS to Weave Scope pods.
- The HTTP Basic Auth annotations (`nginx.ingress.kubernetes.io/auth-type: basic` and `nginx.ingress.kubernetes.io/auth-secret: secret-http-basic-auth`) will be used.

If everything looks good, you might check the K8s `secret` resource and the Let's Encrypt Issuer resources (`certificate`, `certificaterequest`, `order` and `challenge`) details.
```sh
$ kubectl get ingress,secret,certificate,certificaterequest,order -n weave 
$ kubectl describe secret cert-tls -n weave
Name:         cert-tls
Namespace:    weave
Labels:       &lt;none&gt;
Annotations:  cert-manager.io/alt-names: weave-scope.cloud.holisticsecurity.io
              cert-manager.io/certificate-name: cert-tls
              cert-manager.io/common-name: weave-scope.cloud.holisticsecurity.io
              cert-manager.io/ip-sans: 
              cert-manager.io/issuer-kind: Issuer
              cert-manager.io/issuer-name: letsencrypt-issuer-staging
              cert-manager.io/uri-sans: 

Type:  kubernetes.io/tls

Data
====
tls.crt:  3610 bytes
tls.key:  1675 bytes
ca.crt:   0 bytes


$ kubectl describe certificate cert-tls -n weave
...
...
Events:
  Type    Reason        Age    From          Message
  ----    ------        ----   ----          -------
  Normal  GeneratedKey  3m39s  cert-manager  Generated a new private key
  Normal  Requested     3m36s  cert-manager  Created new CertificateRequest resource &quot;cert-tls-3240899713&quot;
  Normal  Issued        2m2s   cert-manager  Certificate issued successfully
```

Now, if you open this url `https://weave-scope.cloud.holisticsecurity.io` in your browser you will get an error about _Certificate desn't Trusted_ and can not get access to Weave Scope. That doesn't mean that Cert-Manager or Ingress Controller don't work, that means specifically this:

&gt; weave-scope.cloud.holisticsecurity.io has a security policy called HTTP Strict Transport Security (HSTS), which    
&gt; means that Firefox can only connect to it securely. You can't add an exceptions to visit this site.
&gt; 
&gt; The issue is most likely with the website, and there is nothing you can do.

[![](/assets/blog20200319/mvp-sec-part2-weave-1-tls-http-basic-auth-fake-cert-error.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-1-tls-http-basic-auth-fake-cert-error.png)
[![](/assets/blog20200319/mvp-sec-part2-weave-2-tls-http-basic-auth-fake-cert-error.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-2-tls-http-basic-auth-fake-cert-error.png)

**3. Create the Ingress resource and getting a Production Certificate**


In this point we are ready to get a certificate for production purposes, before we should remove the previous ingress resource and its corresponding generated secret.
```sh
$ kubectl delete ingress weave-scope-app-ingress -n weave
$ kubectl delete secret cert-tls -n weave
```

Edit the `weave-scope-app-ingress.yaml`.
```sh
$ nano weave-scope-app-ingress.yaml 
```

Uncomment this line `cert-manager.io/issuer: &quot;letsencrypt-issuer-prod&quot;` and comment this other `cert-manager.io/issuer: &quot;letsencrypt-issuer-staging&quot;` in `weave-scope-app-ingress.yaml` file.
```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: weave-scope-app-ingress
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    #cert-manager.io/issuer: &quot;letsencrypt-issuer-staging&quot;
    cert-manager.io/issuer: &quot;letsencrypt-issuer-prod&quot;
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: secret-http-basic-auth
  namespace: weave
spec:
  rules:
  - host: weave-scope.cloud.holisticsecurity.io
    http:
      paths:
      - path: /
        backend:
          serviceName: weave-scope-app-svc-np  ## NodePort
          servicePort: 82
  tls:
  - hosts:
    - weave-scope.cloud.holisticsecurity.io
    secretName: cert-tls
```

Now create the updated ingress.
```sh
$ kubectl apply -f weave-scope-app-ingress.yaml 
```

Check all resources created.
```sh
$ kubectl get ingress,secret,certificate,certificaterequest,order -n weave 
NAME                                         HOSTS                                   ADDRESS   PORTS     AGE
ingress.extensions/weave-scope-app-ingress   weave-scope.cloud.holisticsecurity.io             80, 443   68s

NAME                                        TYPE                                  DATA   AGE
secret/cert-tls                             kubernetes.io/tls                     3      66s
secret/default-token-gzbzs                  kubernetes.io/service-account-token   3      31m
secret/letsencrypt-issuer-privkey-prod      Opaque                                1      24m
secret/letsencrypt-issuer-privkey-staging   Opaque                                1      25m
secret/secret-http-basic-auth               Opaque                                1      27m
secret/weave-scope-token-vb7vg              kubernetes.io/service-account-token   3      31m

NAME                                   READY   SECRET     AGE
certificate.cert-manager.io/cert-tls   True    cert-tls   68s

NAME                                                     READY   AGE
certificaterequest.cert-manager.io/cert-tls-1393507612   True    66s

NAME                                                        STATE   AGE
order.acme.cert-manager.io/cert-tls-1393507612-2800536094   valid   66s
```

Now, if you open this url `https://weave-scope.cloud.holisticsecurity.io` in your browser you will be prompted for user and password to get access to Weave Scope.

[![](/assets/blog20200319/mvp-sec-part2-weave-3-tls-http-basic-auth-ok.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-3-tls-http-basic-auth-ok.png)
[![](/assets/blog20200319/mvp-sec-part2-weave-4-tls-http-basic-auth-info.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-4-tls-http-basic-auth-info.png)

Once authenticated, you will be able to check the TLS Certificate issued by Let's Encrypt.
[![](/assets/blog20200319/mvp-sec-part2-weave-5-tls-http-basic-auth-certificates.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-5-tls-http-basic-auth-certificates.png)
[![](/assets/blog20200319/mvp-sec-part2-weave-6-tls-http-basic-authed.png){:width=&quot;350&quot;}](/assets/blog20200319/mvp-sec-part2-weave-6-tls-http-basic-authed.png)



**4. Troubleshooting with logs**

Check the Cert-Manager logs to see if the TLS Cert, Keys, CSR, etc. were requested and approved successfully.
```sh
$ kubectl logs -f -n cert-manager -lapp=cert-manager
```

Check the NGINX Ingress Controller logs to see if the TLS Cert and configuration were created and loaded successfully.
```sh
$ kubectl logs -f -n ingress-nginx -lapp.kubernetes.io/part-of=ingress-nginx
```


## Conclusions

### You need a PKI

Let's Encrypt technically can issue TLS Client Certificates, but it isn't recommended because using Let’s Encrypt’s DV certificates directly as client certificates doesn’t offer a lot of flexibility, and probably doesn’t enhance overall security in most configurations. The best option would be to use your own CA for this process, as that allows for much more direct control, and client certificates don’t have to be publicly trusted by all clients, just trusted by your server.  
For other side, at operationaly speaking, TLS Certificate Management (revocation, renewals, validation, etc.) is expensive, that means we will require a PKI with a powerful RESTful API to manage the Cert Lifecycle during the deployment of Containers-based Applications.  
A PKI will be helpful allowing to create a private CA or Intermediate CA and manage their Lifecycle easily.

&gt; I use Jetstack Cert-Manager to manage certs issued for Let's Encrypt, Hashicorp Vault and Venafi, in the 2nd post I'll explain how to use Hashicorp Vault as CA for enablling TLS and Mutual TLS Authentication (MTLS) in the services running in Kubernetes Cluster.  
&gt; In the 3rd post I'll explain how to integrate and use Hashicorp Vault as a PKI.

### You need an IAM System

Mutual TLS Authentication (MTLS) is better than HTTP Basic Authentication over TLS, instead of using a pre-shared key with HTTP Basic Authentication, with TLS you are able to use a TLS Client Certificate, in fact to enable MTLS will require to issue 2 certificates (TLS Server and TLS Client Certificates) and deploy TLS configuration to enable authentication for that specified Service or Web Application. That will work perfectly if you have to enable MTLS for few services or applications, but in a scenario where you have several APIs or a Container-based Distributed Application, the task of dealing MTLS will turn very complicated. For that, many Organizations consider adoption of an IAM System like WSO2 Identity Server, KeyCloak, DEX, etc. I recommend have a look for IAM at OSS Product List that I prepared in the post [Security along Container-based SDLC - OSS Tools List](https://holisticsecurity.io/2020/02/10/security-along-the-container-based-sdlc#oss-doc-link).

&gt; In the 4th post I'll explain how to integrate an IAM opensource as OIDC Provider for Kubernetes.

## References

- [Cert-Manager tutorial - Securing NGINX-ingress](https://cert-manager.io/docs/tutorials/acme/ingress)
- [How to Set Up an Nginx Ingress with Cert-Manager on DigitalOcean Kubernetes](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-with-cert-manager-on-digitalocean-kubernetes)</content><author><name></name></author><category term="aws" /><category term="k8s" /><category term="microservice" /><category term="x509" /><category term="tls" /><category term="mvp" /><category term="HTTP Basic Auth" /><summary type="html">In the “Minimum Viable Security for a Kubernetised Webapp: TLS everywhere - Part1” I used the Affordable K8s’ Terraform scripts to create a K8s Cluster with the Jetstack Cert-Manager and the NGINX Ingress Controller pre-installed, now I want to improve the security of a Webapp hosted in that Cluster according the Minimum Viable Security (MVSec) and Pareto Principle or 80/20 rule. In this post I’ll explain how to enable and configure HTTP Basic Authentication over TLS in the Weave Scope webapp running in the recently created K8s Cluster.</summary></entry><entry><title type="html">DevOps is to SDLC as MLOps is to Machine Learning Applications</title><link href="http://localhost:4000/2020/03/10/devops-is-to-sdlc-as-mlops-is-to-machine-learning-apps" rel="alternate" type="text/html" title="DevOps is to SDLC as MLOps is to Machine Learning Applications" /><published>2020-03-10T10:00:00+01:00</published><updated>2020-03-10T10:00:00+01:00</updated><id>http://localhost:4000/2020/03/10/devops-is-to-sdlc-as-mlops-is-to-machine-learning-apps</id><content type="html" xml:base="http://localhost:4000/2020/03/10/devops-is-to-sdlc-as-mlops-is-to-machine-learning-apps">If you have read the previous post about [Security along the Container-based SDLC](https://holisticsecurity.io/2020/02/10/security-along-the-container-based-sdlc), then you have noted that DevOps and Security practices should be applied and embeded along [SDLC](https://en.wikipedia.org/wiki/Systems_development_life_cycle). Before we had to understand the entire software production process and sub-processes in order to apply these DevOps and Security practices. Well, in this post I'll explain how to apply DevOps practices along Machine Learning Software Applications Development Life Cycle (ML-SDLC) and I'll share a set of tools focusing to implement MLOps.

[![](/assets/blog20200309/mlops-sdlc-devsecops-comparison.png)](/assets/blog20200309/mlops-sdlc-devsecops-comparison.png){:target=&quot;_blank&quot;}  
_&lt;center&gt;Data Science (&amp; ML) Life Cycle&lt;/center&gt;_

&lt;!-- more --&gt;

## Concepts and definitions

**Artificial Intelligence**
&gt; Computer science defines AI research as the study of &quot;intelligent agents&quot;: any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. A more elaborate definition characterizes AI as &quot;a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.&quot;  
&gt; [https://en.wikipedia.org/wiki/Artificial_intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence)

**Machine Learning**
&gt; Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead.
&gt; [https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning)

**Inference**
&gt; Inferences are steps in reasoning, moving from premises to logical consequences; etymologically, the word infer means to &quot;carry forward&quot;. Inference is theoretically traditionally divided into deduction and induction.
&gt; [https://en.wikipedia.org/wiki/Inference](https://en.wikipedia.org/wiki/Inference)

**Data Science**
&gt; Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining and big data.  
&gt; Data science is a &quot;concept to unify statistics, data analysis, machine learning and their related methods&quot; in order to &quot;understand and analyze actual phenomena&quot; with data.  
&gt; [https://en.wikipedia.org/wiki/Data_science](https://en.wikipedia.org/wiki/Data_science)


## Data Science (&amp; ML) challenges 

Undoubtedly this era belongs to Artificial Intelligence (AI), and this results in the use of Machine Learning in almost every field, trying to solve different kind of problems from healthcare, in business fields, and technical spaces, Machine Learning is everywhere. That, the Open Source Software (OSS) and Cloud-based Distributed Computing have caused the appearance of many tools, techniques, and algorithms and the ___development of Machine Learning models to solve a problem is not a challenge, the real challenge lies in the management of these models and their data at a massive scale___. 

[![](/assets/blog20200309/PGS-Software-MLOps-2.png){:width=&quot;800&quot;}](/assets/blog20200309/PGS-Software-MLOps-2.png) | More Effective Machine Learning Production with MLOps, December 11, 2019 Maciej Mazur (https://www.pgs-soft.com/blog/more-effective-machine-learning-production-with-mlops)  

The Data Science (&amp; ML) Development Process needs to learn from SDLC (Software Engineering) in order to face these challenges, and What are these challenges?. The answer is: They are the same challenges that SDLC (Software Engineering) is facing by adopting the DevOps Practices, for example:

**1. Data challenges**  
Dataset dependencies. Data in training and in evaluation stages can vary in real-world scenarios.
  
**2. Model challenges**  
ML models are built in a Data scientist sandbox. It was not developed to take scalability in mind; rather, it was just developed to get good accuracies and right algorithm.   
Scale ML Applications.  

**3. Automation**  
Training a simple model and putting it into inference and generating prediction is a simple and manual task. In real-world cases (at scale) that must be automated everything and anywhere.   
Automation is the only way to achieve scalability in the different stages of ML-SDLC.

**4. Observability**  
Monitoring, Alerting, Visualization and Metrics.  

**5. The MLOps Tool Scene**  
The effort involved in solving MLOps challenges can be reduced by leveraging a platform and applying it to the particular case.  
The AI (&amp; ML) tool landscape is complex with different tools specialising in different niches and in some cases there are competing tools approaching similar problems in different ways (see the below Linux Foundation's AI project for a categorised lists of tools).

[![](/assets/blog20200309/202003109-linux-foundation-ai-landscape.png)](/assets/blog20200309/202003109-linux-foundation-ai-landscape.png){:target=&quot;_blank&quot;}  
_&lt;center&gt;The Linux Foundation's AI (&amp; ML) tool landscape - 2020/03/09&lt;/center&gt;_


## What is MLOps?

&gt; MLOps (a compound of “machine learning” and “operations”) is a practice for collaboration and communication between data scientists and operations professionals to help manage production ML (or deep learning) lifecycle.[1] Similar to the DevOps or DataOps approaches, MLOps looks to increase automation and improve the quality of production ML while also focusing on business and regulatory requirements. While MLOps also started as a set of best practices, it is slowly evolving into an independent approach to ML lifecycle management. MLOps applies to the entire lifecycle - from integrating with model generation (software development lifecycle, continuous integration/continuous delivery), orchestration, and deployment, to health, diagnostics, governance, and business metrics. 
&gt; [https://en.wikipedia.org/wiki/MLOps](https://en.wikipedia.org/wiki/MLOps)


## Selected tools to support MLOps and criteria used

If you have reviewed above [The Linux Foundation’s AI project landscape (categorised lists of tools)](https://landscape.lfai.foundation/images/landscape.png), you have realized that there a plenty of different tools, commercial and opensource. Well, the next list of products is a subset of products that follow this criteria:

**1. Open Source**  
Perfect for early adopters, also suitable to implement easily Proof-of-concepts or starting your own personal project.

**2. Kubernetes-based**  
Kubernetes and Containers are the new platform where our Applications are going to run and live, even the ML Applications.

**3. Platform**  
I don’t want to waste efforts integrating heterogeneous tools, I want a stack or platform with mature tools already integrated seamlessly.


[](){:name=&quot;oss-doc-link&quot;}

&lt;iframe src=&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vTXcNBZjmHMfFHGmwizy_olJ0WP3aOA_lax4lRe9Y1DjG7XARstwm53ovFaovkirt7ybeyq8ybr9Tck/pubhtml?widget=true&amp;amp;headers=false&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/iframe&gt;
_&lt;center&gt;Open Source Tools (Platforms) to support the MLOps&lt;/center&gt;_

## References


* [What would machine learning look like if you mixed in DevOps? Wonder no more, we lift the lid on MLOps - By Ryan Dawson, 7 Mar 2020](https://www.theregister.co.uk/2020/03/07/devops_machine_learning_mlops)
* [MLOps Platform: Productionizing Machine Learning Models - By Navdeep Singh Gill, 2 Sep 2019](https://www.xenonstack.com/blog/mlops)
* [ML Ops: Machine Learning as an Engineering Discipline - By Cristiano Breuel, 3 Jan 2020](https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f)
* [MLOps: CI/CD for Machine Learning Pipelines &amp; Model Deployment with Kubeflow - 25 Oct 2019](https://growingdata.com.au/mlops-ci-cd-for-machine-learning-pipelines-model-deployment-with-kubeflow)
* [The Linux Foundation’s AI project landscape (categorised lists of tools)](https://landscape.lfai.foundation/images/landscape.png)
* [The Institute for Ethical AI &amp; Machine Learning - Awesome production machine learning](https://github.com/EthicalML/awesome-production-machine-learning)</content><author><name></name></author><category term="Kubernetes" /><category term="MLOps" /><category term="CI/CD" /><summary type="html">If you have read the previous post about Security along the Container-based SDLC, then you have noted that DevOps and Security practices should be applied and embeded along SDLC. Before we had to understand the entire software production process and sub-processes in order to apply these DevOps and Security practices. Well, in this post I’ll explain how to apply DevOps practices along Machine Learning Software Applications Development Life Cycle (ML-SDLC) and I’ll share a set of tools focusing to implement MLOps. Data Science (&amp;amp; ML) Life Cycle</summary></entry><entry><title type="html">Minimum Viable Security for a Kubernetised Webapp: TLS everywhere - Part1</title><link href="http://localhost:4000/2020/03/08/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part1" rel="alternate" type="text/html" title="Minimum Viable Security for a Kubernetised Webapp: TLS everywhere - Part1" /><published>2020-03-08T10:00:00+01:00</published><updated>2020-03-08T10:00:00+01:00</updated><id>http://localhost:4000/2020/03/08/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part1</id><content type="html" xml:base="http://localhost:4000/2020/03/08/minimum-viable-security-for-a-k8s-webapp-tls-everywhere-part1">__Minimum Viable Security__ (MVSec) is a concept borrowed from the [Minimum Viable Product](https://en.wikipedia.org/wiki/Minimum_viable_product){:target=&quot;_blank&quot;} (MVP) concept about the Product Development Strategy and from the [Pareto Principle or 80/20 rule](https://en.wikipedia.org/wiki/Pareto_principle){:target=&quot;_blank&quot;}. The MVP concept applied to IT Security means the product (application) will contain only the minimum amount (20%) of effort invested in order to prove the viability (80%) of an idea (acceptable security). 

The purpose of this post is to explain how to implement __TLS everywhere__ to become __MVSec__ (roughly 80% of security with 20% of working) for a __Kubernetised Webapp hosted on AWS__.

[![](/assets/blog20200308/minimum-viable-security-pareto-tls-everywhere-kubernetised-webapp.png)](/assets/blog20200308/minimum-viable-security-pareto-tls-everywhere-kubernetised-webapp.png){:target=&quot;_blank&quot;}  
_&lt;center&gt;Minimum Viable Security for a Kubernetised Webapp: TLS everywhere with NGINX Ingress Controller, Cert-Manager and Let's Encrypt&lt;/center&gt;_

&lt;!-- more --&gt; 

## Why _TLS everywhere_ meets 80/20 rule?

Part of the answer gives us Vilfredo Pareto with the Pareto Principle, but to have a complete answer we have to turn to The Security Design Principles that NIST, OWASP, NCSC and other Security References give us.  

&gt; The Security Design Principles to consider are:
&gt; - [Building Secure Software: How to Avoid Security Problems the Right Way by Gary McGraw, John Viega, released September 2001](https://www.oreilly.com/library/view/building-secure-software/9780672334092) and the [&quot;Exploiting Software: How to Break Code&quot;](/assets/blog20200308/20200308-exploiting-software-how-to-break-code-2004-gary-mcgraw-cigital.pdf) Presentation by Gary McGrow, 2004.
&gt; - OWASP Security by Design Principles:
&gt;   * [10 Security Principles, archived by 2016 ](https://wiki.owasp.org/index.php/Security_by_Design_Principles)
&gt;   * [11 Security Principles, updated by October 2015](https://github.com/OWASP/DevGuide/blob/master/02-Design/01-Principles%20of%20Security%20Engineering.md)
&gt; - [Systems Security Engineering by NIST, SP 800-160 Vol. 1, updated 21/Mar/2018](https://csrc.nist.gov/publications/detail/sp/800-160/vol-1/final):
&gt;   * There are 32 principles.
&gt; - [Secure Design Principles by NCSC, version 1.0, updated 21/May/2019](https://www.ncsc.gov.uk/collection/cyber-security-design-principles): 
&gt;   * There are 31 and 15 principles in total.
&gt; - [Cliff Berg’s Principles for High-Assurance Design (Architecting Secure and Reliable Enterprise Applications), 23/October/2005](https://www.amazon.com/High-Assurance-Design-Architecting-Enterprise-Applications/dp/0321793277), etc.
  
There are many similarities between them at fundamental level, let's explore the OWASP for example and do a quick analysis to see how TLS can help us to meet these Security Principles.

OWASP Security Design Principles| Explanation                   | How to TLS help us?
---                             | ---                           | ---
1) Defense in Depth.            | Also known as layered defense.| TLS over HTTP provides a new secure layer.
2) Fail Safe.                   | Unless a subject is given explicit access to an object, it should be denied access to that object. | TLS Certificates can encrypt at rest and in transit these objects.
3) Least Privilege.             | A Process is given only the minimum level of access rights (privileges) that is necessary for that Process to complete an assigned operation. | Transit of sensitive objects must be over TLS.
4) Separation of Duties.        | Also known as the [compartmentalization principle](https://en.wikipedia.org/wiki/Compartmentalization_(information_security)), or separation of privilege. | HTTPS is for sensitive transactions and HTTP for non-sensitive.
5) Economy of Mechanism.        | Also known as [Keep It Simple, Stupid principle](https://en.wikipedia.org/wiki/KISS_principle). | The accepted and supported [HTTP/2](https://en.wikipedia.org/wiki/HTTP/2) includes TLS by default. So, if HTTP is insecure, why is it still being used?.
6) Complete Mediation.          | All accesses to objects must be checked to ensure that they are allowed. | TLS provides Simple and [Mutual (Two-Way) Authentication](https://en.wikipedia.org/wiki/Mutual_authentication) and allways once crypto keys have been verified a secure communication is stablished. 
7) Open Design.                 | The security of a mechanism should not depend on the secrecy of its design or implementation. | The disclosure of TLS' using in software designs don't put in risk the application.
8) Least Common Mechanism       | It disallows the sharing of mechanisms that are common to more than one user or process if the users and processes are at different levels of privilege. | TLS is a common secure mechanism shared along the application.
9) Psychological acceptability. | Tries maximizing the usage and adoption of the security functionality in the application by making it more usable. | TLS is a feature by default in HTTP/2. HTTP requires implement TLS and deal the crypto keys.  
10) Weakest Link.               | The resiliency of your software against hacker attempts will depend heavily on the protection of its weakest components. | TLS helps to harden the access to resources and secure the traffic.
11) Leveraging Existing Components. | It focuses on ensuring that the attack surface is not increased. | TLS is a feature by default in HTTP/2 for securing data in transit and data at rest, don't try to bring or implement your own _TLS_.

If this quick analysis does not convince you, then refer to the [Pillars of Security](https://en.wikipedia.org/wiki/Information_security), they are axioms and don't require be demostration.
Organization like OWASP recommends that all security controls should be designed with the __Core pillars of Information Security__ in mind:

Pillar of Security | Description                                                                   | How TLS apply?
---                | ---                                                                           | ---
1. Confidentiality | Only allow access to data for which the user is permitted.                    | Access Control(*) using TLS and Mutual TLS Authn.
2. Integrity       | Ensure data is not tampered or altered by unauthorised users.                 | Data no altered using TLS(*) encryption at rest.
3. Availability    | Ensure systems and data are available to authorised users when they need it.  | Mutual TLS Authn(*) helps to availability only to authorised users.

&gt; (*) These Axioms refer to _access control_, _data no altered_, _unauthorised users_, etc. and that is implemented following the [Identity-based Security](https://en.wikipedia.org/wiki/Identity-based_security) Strategy.

## Let's implement TLS everywhere in Kubernetes.

### Create an Kubernetes Cluster

This blog post will use the &quot;Building your own affordable K8s - Serie&quot;:
- [Part 1 - Building your own affordable K8s to host a Service Mesh](/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane){:target=&quot;_blank&quot;}.
- [Part 2 - Building your own affordable K8s - ExternalDNS and NGINX as Ingress](/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress){:target=&quot;_blank&quot;}.
- [Part 3 - Building your own affordable K8s - Certificate Manager](/2020/01/29/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part3-certificate-manager){:target=&quot;_blank&quot;}.


**1) Clone the Affordable K8s Cluster Git Repo and run the Terraform scripts**

I'll create a Kubernetes Cluster with this configuration:

- NGINX Ingress Controller will be deployed as `DaemonSet` (in the namespace `ingress-nginx`) with `hostNetwork: true` to ensure the NGINX server is reachable from all K8s Cluster nodes.
  * When a pod is configured with `hostNetwork: true`, the applications running in such a pod can directly see the network interfaces of the host machine where the pod was started.
  * Further information in the [`nginx-ingress-mandatory.yaml` deployment file](https://github.com/chilcano/affordable-k8s/blob/master/manifests/nginx-ingress-mandatory.yaml).
- Custom Domain Name System (DNS) is `cloud.holisticsecurity.io` and the Ingress Subdomain DNS is `ingress-nginx.cloud.holisticsecurity.io`.
- TLS Cert enabled using Jetstack Cert-Manager and Let's Encrypt.
- `NodePort` Service for the NGINX Ingress Controller. See its [configuration](https://github.com/chilcano/affordable-k8s/blob/master/manifests/nginx-ingress-nodeport.yaml.tmpl) here.

```sh
$ git clone https://github.com/chilcano/affordable-k8s
$ cd affordable-k8s

$ terraform init

$ terraform plan \
  -var cluster_name=&quot;cheapk8s&quot; \
  -var k8s_ssh_key=&quot;ssh-key-for-us-east-1&quot; \
  -var admin_cidr_blocks=&quot;&lt;YOUR-IP-ADDRESS&gt;/32&quot; \
  -var region=&quot;us-east-1&quot; \
  -var kubernetes_version=&quot;1.14.3&quot; \
  -var external_dns_enabled=&quot;1&quot; \
  -var nginx_ingress_enabled=&quot;1&quot; \
  -var nginx_ingress_domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; \
  -var cert_manager_enabled=&quot;1&quot; \
  -var cert_manager_email=&quot;cheapk8s@holisticsecurity.io&quot;

$ terraform apply \
  -var cluster_name=&quot;cheapk8s&quot; \
  -var k8s_ssh_key=&quot;ssh-key-for-us-east-1&quot; \
  -var admin_cidr_blocks=&quot;&lt;YOUR-IP-ADDRESS&gt;/32&quot; \
  -var region=&quot;us-east-1&quot; \
  -var kubernetes_version=&quot;1.14.3&quot; \
  -var external_dns_enabled=&quot;1&quot; \
  -var nginx_ingress_enabled=&quot;1&quot; \
  -var nginx_ingress_domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; \
  -var cert_manager_enabled=&quot;1&quot; \
  -var cert_manager_email=&quot;cheapk8s@holisticsecurity.io&quot;
```

**2) Checking the K8s Cluster, NGINX Ingress Controller, Cert-Manager are running correctly**


```sh
// SSH to the cluster
$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem
```

Checking NGINX Ingress Controller:
```sh
// Likely you have to wait a 2-3 minutes till the Cluster is running completely.
$ kubectl get pod,svc -n ingress-nginx -o wide
NAME                                        READY   STATUS    RESTARTS   AGE
pod/default-http-backend-5c9bb94849-9lpn9   1/1     Running   0          7m35s
pod/nginx-ingress-controller-r2j8t          1/1     Running   0          7m34s
pod/nginx-ingress-controller-v22mp          1/1     Running   0          7m34s

NAME                           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/default-http-backend   ClusterIP   10.110.233.145   &lt;none&gt;        80/TCP                       7m36s
service/ingress-nginx          NodePort    10.111.197.179   &lt;none&gt;        80:30002/TCP,443:30414/TCP   7m33s
```

If everything is fine, you should get a `default backend - 404` response when accessing the NGINX Ingress Controller using its `NodePort` and its `external IP address`. This tells us that the controller doesn’t know where to route the request to, so responds with the default backend.

```sh
// Calling it from inside the K8s Cluster, here you have to use the `NodePorts` (`30002` for HTTP and `30414` for HTTPS):
$ curl http://localhost:30002/abc
default backend - 404

$ curl https://localhost:30414/pqr -k
default backend - 404

// Calling from Internet, here you have to use `80` and `443` port, and the FQDN `ingress-nginx.cloud.holisticsecurity.io`
$ curl http://ingress-nginx.cloud.holisticsecurity.io/abc
default backend - 404

$ curl https://ingress-nginx.cloud.holisticsecurity.io/pqr -k
default backend - 404
```

Checking Cert-Manager:
```sh
// Cert-Manager logs
$ kubectl logs -f -n cert-manager -lapp=cert-manager

// Lets Encrypt Cert Issuer
$ kubectl get issuer,secret -n default
```

### Deploying a Sample Application

I love [Weave Scope](https://www.weave.works/docs/scope/latest/introducing), it is a good Web Application that I can use as example to enable/configure its security.

&gt; __Weave Scope__ is a visualization and monitoring tool for Docker and Kubernetes. It provides a top down view into your app as well as your entire infrastructure, and allows you to diagnose any problems with your distributed containerized app, in real time, as it is being deployed to a cloud provider.

**Installing Weave Scope**  
```sh
# Get ssh access and in your K8s Cluster, run below command to install Weave Scope with everything by default.
$ kubectl apply -f &quot;https://cloud.weave.works/k8s/scope.yaml?k8s-version=$(kubectl version | base64 | tr -d '\n')&quot;

# Check if Weave Scope has been installed successfully. You will see Pods, Service, ReplicaSet, DaemonSet and Deployment.
$ kubectl get all -n weave

# Get the Weave Scope's TargetPort. By default the TargetPort for Weave Scope's ClusterIP service is 4040.
$ kubectl get -n weave svc weave-scope-app -o jsonpath='{.spec.ports[0].targetPort}'
4040
```

**Creating NodePort service for Weave Scope**  
Since `ClusterIP` is for internal use only, I'll need that Weave Scope be exposed and reachable from Internet that I can make a SSH tunnel. I can do it by creating a new `NodePort` service, also I'll create and register in AWS Route 53 a fqdn for Weave-Scope, in this case it will be `weave-scope.cloud.holisticsecurity.io`, although this fqdn isn't required to make the SSH tunnel.
```sh
# Let's create a NodePort Resource for Weave Scope.
$ kubectl apply -f https://raw.githubusercontent.com/chilcano/affordable-k8s/master/examples/weave-scope-app-svc-np.yaml
service/weave-scope-app-svc-np created

# Now, we have 2 services
$ kubectl get svc -n weave
NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
weave-scope-app        ClusterIP   10.100.187.247   &lt;none&gt;        80/TCP         45m
weave-scope-app-svc-np NodePort    10.102.182.243   &lt;none&gt;        80:30002/TCP   18m

# Get the Weave Scope's NodePort. Also you can see it in above command or in the 'sample-2-weave-scope-app-svc-np.yml' file.
$ kubectl get -n weave svc weave-scope-app-svc-np -o jsonpath='{.spec.ports[0].nodePort}'
30002
```

**Creating a SSH tunnel to Weave Scope**  
Now let's create a SSH tunnel from your Admin Computer over Internet to Weave Scope's NodePort service. 
```sh
$ ssh -nNT -L 4002:localhost:30002 ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem
```

Now open your favorite browser and enter this url [http://localhost:4002](http://localhost:4002){:target=&quot;_blank&quot;} and you will be able to visualize all resources created in your Cluster in real-time.

[![](/assets/blog20200308/20200308-tls-everywhere-part1-weave-scope-ssh-tunnel.png){:width=&quot;80%&quot;}](/assets/blog20200308/20200308-tls-everywhere-part1-weave-scope-ssh-tunnel.png){:target=&quot;_blank&quot;}


### Enabling and configuring Security based on TLS

Since I'm using the [Affordable K8s](https://github.com/chilcano/affordable-k8s)' Terraform scripts to build a K8s Cluster with the Jetstack Cert-Manager, to get, renew, revoke any kind of X.509 Certificates, and the NGINX Ingress Controller, to manage the traffic, now i would be able to improve security according the __Minimum Viable Security__ (MVSec) and __Pareto Principle or 80/20 rule__ both explained above.  
In next posts I'll explain how to:

* **Part 1 - Minimum Viable Security for a Kubernetised Webapp: TLS everywhere** (this post)
* **Part 2 - Enable and configure [HTTP Basic Authentication](https://en.wikipedia.org/wiki/Basic_access_authentication) over TLS in Weave Scope**
* **Part 3 - Enable and configure [Mutual TLS Authentication](https://en.wikipedia.org/wiki/Mutual_authentication) in Weave Scope**
* **Part 4 - Use Hashicorp Vault as PKI and Secrets Management in a Kubernetised Webapp**
* **Part 4 - Integrating an IAM (Identity Access Management - see [Security along Container-based SDLC - OSS Tools List](https://holisticsecurity.io/2020/02/10/security-along-the-container-based-sdlc#oss-doc-link)) solution in a Kubernetised Webapp**


## Troubleshooting

1. Getting Kubernetes installation logs:
   Access to Cluster via SSH and get the logs.
   ```sh
   $ cat /var/log/cloud-init-output.log
   ```
2. Getting NGINX Ingress Controller logs:
   ```sh
   $ kubectl get pods -n ingress-nginx 
   $ kubectl exec -it -n ingress-nginx nginx-ingress-controller-p5qz5 -- cat /etc/nginx/nginx.conf | grep ssl
   $ kubectl logs -f -n ingress-nginx nginx-ingress-controller-p5qz5 | grep Error
   $ kubectl logs -f -n ingress-nginx -lapp.kubernetes.io/name=ingress-nginx
   $ kubectl logs -f -n ingress-nginx -lapp.kubernetes.io/part-of=ingress-nginx
   ```
3. Getting Jetstack Cert-Manager logs:
   ```sh
   $ kubectl get pods -n cert-manager
   $ kubectl exec -it -n ingress-nginx cert-manager-54d94bb6fc-fmhcc -- cat /etc/nginx/nginx.conf | grep ssl
   $ kubectl logs -f -n cert-manager cert-manager-54d94bb6fc-fmhcc 
   $ kubectl logs -f -n cert-manager -lapp=cert-manager
   $ kubectl logs -f -n cert-manager -lapp=cainjector
   $ kubectl logs -f -n cert-manager -lapp=webhook
   ```</content><author><name></name></author><category term="aws" /><category term="kubernetes" /><category term="microservice" /><category term="x509" /><category term="tls" /><category term="mvp" /><summary type="html">Minimum Viable Security (MVSec) is a concept borrowed from the Minimum Viable Product (MVP) concept about the Product Development Strategy and from the Pareto Principle or 80/20 rule. The MVP concept applied to IT Security means the product (application) will contain only the minimum amount (20%) of effort invested in order to prove the viability (80%) of an idea (acceptable security). The purpose of this post is to explain how to implement TLS everywhere to become MVSec (roughly 80% of security with 20% of working) for a Kubernetised Webapp hosted on AWS. Minimum Viable Security for a Kubernetised Webapp: TLS everywhere with NGINX Ingress Controller, Cert-Manager and Let's Encrypt</summary></entry><entry><title type="html">Security along the Container-based SDLC</title><link href="http://localhost:4000/2020/02/10/security-along-the-container-based-sdlc" rel="alternate" type="text/html" title="Security along the Container-based SDLC" /><published>2020-02-10T10:00:00+01:00</published><updated>2020-02-10T10:00:00+01:00</updated><id>http://localhost:4000/2020/02/10/security-along-the-container-based-sdlc</id><content type="html" xml:base="http://localhost:4000/2020/02/10/security-along-the-container-based-sdlc">Nowadays, containers are becoming the standard deployment unit of software, and that in the Cloud-based Application Security world means 2 things:

* The Software Applications are **distributed** into containers.
* The minimum unit of **deployment** and **shipment** is the container.

In other words, using containers we are adding a new element to be considered along the [Software Development Life Cycle (SDLC)](https://en.wikipedia.org/wiki/Systems_development_life_cycle){:target=&quot;_blank&quot;} as a new additional piece of software (containers), and from Architectural point of view, those new pieces of software will be distributed.

Said that, the purpose of this post is explain you how to embed **Security along the Container-based SDLC (Secure-SDLC)** and how to **DevOps** practices will help its adoption.

[![](/assets/blog20200210/20200210-security-along-container-based-sdlc-v2.png)](/assets/blog20200210/20200210-security-along-container-based-sdlc-v2.png){:target=&quot;_blank&quot;}   
_&lt;center&gt;Security along the Container-based SDLC - Overview&lt;/center&gt;_

&lt;!-- more --&gt; 

The above Secure-SDLC diagram was created using the classic [Systems development life cycle published at Wikipedia](https://en.wikipedia.org/wiki/Systems_development_life_cycle){:target=&quot;_blank&quot;} and software engineering and security-related techniques such as:

- [The Twelve-Factor App](https://12factor.net){:target=&quot;_blank&quot;} is a methodology for building software-as-a-service apps.
- [SP 800-190 - Application Container Security Guide - By NIST, September 2017](https://csrc.nist.gov/publications/detail/sp/800-190/final){:target=&quot;_blank&quot;}.
- [Exploring container security: An overview - By Maya Kaczorowski, Security &amp; Privacy Product Manager at Google, March 2018](https://cloud.google.com/blog/products/gcp/exploring-container-security-an-overview){:target=&quot;_blank&quot;}.
- Container Security — From Image Analysis to Network Segmentation, Options Are Maturing - By Gartner, August 2018
   * [Gartner Research](https://www.gartner.com/en/documents/3888664/container-security-from-image-analysis-to-network-segmen){:target=&quot;_blank&quot;}.
   * [Joerg Fritsch's tweet](https://twitter.com/with_joerg/status/1034528900972507138){:target=&quot;_blank&quot;}.
- Some thoughts picked from my [QA and Security in Development Process](https://www.slideshare.net/rcarhuatocto/qa-and-security-in-development-process){:target=&quot;_blank&quot;} presented on July 2005 (Spanish).


## Security-related Techniques and Practices

In the above picture you can see some security-related techniques and practices used in traditional security approaches that still can and must use. Yes, there are not nothing new. The only thing that changes are the tools. Below, at the end of post, you will see a list of *open source security tools* that can be used in each security technique proposed in the *Secure-SDLC*.

**SAST (Static Application Security Testing)**, also known as “white box testing” has been around for more than a decade.  
**DAST (Dynamic Application Security Testing)**, also known as “black box” testing, can find security vulnerabilities and weaknesses in a running application, typically web apps. 
&gt; [https://en.wikipedia.org/wiki/Dynamic_application_security_testing](https://en.wikipedia.org/wiki/Dynamic_application_security_testing){:target=&quot;_blank&quot;}

**IAST (Interactive Application Security Testing)**.
&gt; [https://en.wikipedia.org/wiki/Application_security](https://en.wikipedia.org/wiki/Application_security){:target=&quot;_blank&quot;}

**RASP (Run-time Application Security Protection)**. Run­time Application Security Protection, works inside the application, but it is less a testing tool and more a security tool. It's plugged into an application or its run­time environment and can control application execution. That allows RASP to protect the app even if a network's perimeter defenses are breached and the apps contain security vulnerabilities missed by the development team. RASP lets an app run continuous security checks on itself and respond to live attacks by terminating an attacker’s session and alerting defenders to the attack.
&gt; [https://en.wikipedia.org/wiki/Runtime_application_self-protection](https://en.wikipedia.org/wiki/Runtime_application_self-protection]){:target=&quot;_blank&quot;}

**Misuse cases**. 
&gt; [https://en.wikipedia.org/wiki/Misuse_case](https://en.wikipedia.org/wiki/Misuse_case){:target=&quot;_blank&quot;}

**Abuse cases**. 
&gt; [https://en.wikipedia.org/wiki/Abuse_case](https://en.wikipedia.org/wiki/Abuse_case){:target=&quot;_blank&quot;}

**Intrusion Detection System (IDS)**
&gt; [https://en.wikipedia.org/wiki/Intrusion_detection_system](https://en.wikipedia.org/wiki/Intrusion_detection_system){:target=&quot;_blank&quot;}

**Software Composition Analysis (SCA) / Software Supply Chain**
&gt; [https://owasp.org/www-community/Component_Analysis](https://owasp.org/www-community/Component_Analysis){:target=&quot;_blank&quot;}
&gt; [https://cloud.google.com/solutions/secure-software-supply-chains-on-google-kubernetes-engine](https://cloud.google.com/solutions/secure-software-supply-chains-on-google-kubernetes-engine){:target=&quot;_blank&quot;}


## From Old-school SDLC to Container-based Secure-SDLC

Three things to consider:

### Mixing old with new, adapt old to new along all stages

One of OWASP Security Principles I allways use is [Minimise the Attack Surface (Leveraging existing components)](https://github.com/OWASP/DevGuide/blob/master/02-Design/01-Principles%20of%20Security%20Engineering.md), but since I'm using container as a new element in the software development process, I have to adapt existing techniques and frameworks to mitigate the new attack vectors that container brings. That means mixing old with new and adapt old to new along all stages, for example:

1. We do Static Code Analysis, now we have to consider container's definition and its dependencies.
2. We do Application Testing and Pentesting and we have to extend Pentesting to Application into containers.
3. We do Network Segmentation and Isolation, now we have to consider a new level of segmentation and isolation that container brings.
4. We do Monitor the performance and activity of Applications, now we have to do the same but at container level and at distributed way, etc.

### Security is a process, not a product

Buying and deploying a new Security Tool will not guarantee to solve all security problems because security means different things in different stages in the SDLC and it isn't a problem absolute.
We know that every year come new security problems and new attack vectors, it is impossible to get &quot;Absolute Security&quot;. For that, we have to embed security in all stages of SDLC because [Security is a Process, not a Product](https://www.schneier.com/essays/archives/2000/04/the_process_of_secur.html){:target=&quot;_blank&quot;}.

### From DevOps to DevSecOps

DevOps is a culture of collaboration between teams, Developers and Operations who have traditionally operated in isolated groups working together towards a common goal: release software faster and more reliably.

But what about security?. Security people also work towards to same goal. Then why they don't work together where everyone is responsible for security. If so, that will allow teams release software faster, reliably and secure.

## Open Source Container Security Tools

The criteria I'm going to use to select the tools are:

1. Adaptable or ready to be used with containers.
2. DevOps friendly.
3. Recommended to be used with The Best Security Practices (OWASP, NIST, CIS, etc.)
4. Open Source.

[](){:name=&quot;oss-doc-link&quot;}

&lt;iframe src=&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vRTLn8bLX-Sp6JEbKcJIludCb6wJbTM-5xV5te94srdYnmLYutCu9vcgmiWcc2taioH5cJcj2xXH_Ba/pubhtml?widget=true&amp;amp;headers=false&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/iframe&gt;

&gt; [See whole Sheet (read only)&amp;nbsp;&amp;gt;&amp;gt;](/assets/pages/2020-02-10-security-along-the-container-based-sdlc-oss-tool-list-ro)  
&gt; If don't see a open source security product in the document that is worth being reviewed, please, drop me an email and I'll add to document and review it.

## Conclusions

 1. Although you can do it, you shouln'd use all those open source security tools without outlining your SDLC before, without identifying the security challenges you want to face in each SDLC' stage and without to identifying the existing security practices you are using. 
 2. The [Container has certain inherent characteristics that impact the way the application behaves](https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper){:target=&quot;_blank&quot;}, its misuse may create breachs that can be exploited. Make sure to review the way that container images are created in early SDLC' stages and to use [RASP](https://en.wikipedia.org/wiki/Runtime_application_self-protection){:target=&quot;_blank&quot;} approach in lastly SDLC' stages. 
 3. Since the containers are immutable and ephemeral, the CI/CD processes are shorters in order to deliver new pieces of applications, their updates and their dependencies. In fact, these processes without control are a common attack vector (weakest link) frequently used to introduce untrusted, unpatched, insecure third-party software. Then, make sure to adopt a [Software Composition Analysis (SCA) / Software Supply Chain](https://owasp.org/www-community/Component_Analysis){:target=&quot;_blank&quot;} practice and a tool or framework.


That's it, I hope it helpful. In the next post I'll explain how use some of them.
Stay tuned.

## References

1. [33(+) K8s Security Tools - Sysdig / Mateo Burillo / July 2019](https://sysdig.com/blog/33-kubernetes-security-tools){:target=&quot;_blank&quot;}.
2. [Kali Linux Tools Listing](https://tools.kali.org/tools-listing){:target=&quot;_blank&quot;}.
3. [Top 10 Open Source Security Testing Tools for Web Applications - Hackr.io / Youssef Nader / Last Updated 05 Feb, 2020](https://hackr.io/blog/top-10-open-source-security-testing-tools-for-web-applications){:target=&quot;_blank&quot;}.
4. [Awesome Penetration Testing / Nick Raienko](https://github.com/enaqx/awesome-pentest){:target=&quot;_blank&quot;}.</content><author><name></name></author><category term="kubernetes" /><category term="container" /><category term="microservice" /><category term="sca" /><category term="pentesting" /><category term="SAST" /><category term="DAST" /><category term="IAST" /><category term="RASP" /><summary type="html">Nowadays, containers are becoming the standard deployment unit of software, and that in the Cloud-based Application Security world means 2 things: The Software Applications are distributed into containers. The minimum unit of deployment and shipment is the container. In other words, using containers we are adding a new element to be considered along the Software Development Life Cycle (SDLC) as a new additional piece of software (containers), and from Architectural point of view, those new pieces of software will be distributed. Said that, the purpose of this post is explain you how to embed Security along the Container-based SDLC (Secure-SDLC) and how to DevOps practices will help its adoption. Security along the Container-based SDLC - Overview</summary></entry><entry><title type="html">Building your own affordable K8s to host a Service Mesh - Part 3: Certificate Manager</title><link href="http://localhost:4000/2020/01/29/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part3-certificate-manager" rel="alternate" type="text/html" title="Building your own affordable K8s to host a Service Mesh - Part 3: Certificate Manager" /><published>2020-01-29T10:00:00+01:00</published><updated>2020-01-29T10:00:00+01:00</updated><id>http://localhost:4000/2020/01/29/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane-part3-certificate-manager</id><content type="html" xml:base="http://localhost:4000/2020/01/29/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part3-certificate-manager">In this blog post I'll explain how to get a X.509 TLS Certificate from [Let's Encrypt](https://letsencrypt.org){:target=&quot;_blank&quot;} automatically during the Terraform provision time, in this way we can now invoke the services additionally on port 443 (HTTPS/TLS).  
During the Terraform execution, immediately after Kubernetes Cluster creation, the [JetStack Cert-Manager](https://github.com/jetstack/cert-manager){:target=&quot;_blank&quot;} is deployed in a Pod, it is who will request to [Let's Encrypt](https://letsencrypt.org){:target=&quot;_blank&quot;} service a X.509 TLS Certificate, once completed, the [JetStack Cert-Manager](https://github.com/jetstack/cert-manager){:target=&quot;_blank&quot;} will inject the X.509 Certificate as a Kubernetes Secret into NGINX Ingress Controller to enbale TLS.

At this point you must have created a Kubernetes Cluster with ExternalDNS and NGINX as Ingress Controller. If you don't know how to achieve that, I recommend to follow these posts:

* [Part 1 - Building your own affordable K8s to host a Service Mesh](http://holisticsecurity.io/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane){:target=&quot;_blank&quot;}.
* [Part 2 - Building your own affordable K8s - ExternalDNS and NGINX as Ingress](http://holisticsecurity.io/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress){:target=&quot;_blank&quot;}.

[![K8s Cluster created using AWS Spot Instances - Cert-Manager and Let's Encrypt](/assets/img/20200129-affordablek8s-aws-01-arch-ingress-dns-tls-cert-manager.png &quot;K8s Cluster created using AWS Spot Instances - Cert-Manager and Let's Encrypt&quot;)](/assets/img/20200129-affordablek8s-aws-01-arch-ingress-dns-tls-cert-manager.png){:target=&quot;_blank&quot;}

&lt;!-- more --&gt;

## Steps

### 1. Cleaning everything

If you are using the Terraform scripts to create an affordable K8s Cluster I've forked and updated for you, then first of all you should clean up to start creating a new fresh K8s Cluster for following this scenario.

&gt; If you want a cheap K8s Infrastructure on AWS, I recommend to use this GitHub repo I've updated for you:
&gt; [https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano](https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano)


Removing existing K8s Cluster.
```sh
$ terraform destroy \
  -var cluster-name=&quot;cheapk8s&quot; \
  -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
  -var admin-cidr-blocks=&quot;83.50.13.174/32&quot; \
  -var region=&quot;us-east-1&quot; \
  -var kubernetes-version=&quot;1.14.3&quot; \
  -var external-dns-enabled=&quot;1&quot; \
  -var nginx-ingress-enabled=&quot;1&quot; \
  -var nginx-ingress-domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; 
```

If you have destroyed the K8s Cluster with `terraform destroy`, likely you have to remove unwanted records (created for your services) in the AWS Hosted Zone.
```sh
$ export MY_SUBDOMAIN=&quot;cloud.holisticsecurity.io&quot;
$ export HZ_ID=$(aws route53 list-hosted-zones-by-name --dns-name &quot;${MY_SUBDOMAIN}.&quot; | jq -r '.HostedZones[0].Id')
$ aws route53 list-resource-record-sets --hosted-zone-id $HZ_ID --query &quot;ResourceRecordSets[?Name != '${MY_SUBDOMAIN}.']&quot; | jq -c '.[]' |
  while read -r RRS; do
    read -r name type &lt;&lt;&lt; $(jq -jr '.Name, &quot; &quot;, .Type' &lt;&lt;&lt; &quot;$RRS&quot;) 
    CHG_ID=$(aws route53 change-resource-record-sets --hosted-zone-id $HZ_ID --change-batch '{&quot;Changes&quot;:[{&quot;Action&quot;:&quot;DELETE&quot;,&quot;ResourceRecordSet&quot;: '&quot;$RRS&quot;' }]}' --output text --query 'ChangeInfo.Id')
    echo &quot; - DELETING: $type $name - CHANGE ID: $CHG_ID&quot;    
  done
```

For further details and an explanation about above step review this post:
* [Part 2 - Building your own affordable K8s - ExternalDNS and NGINX as Ingress](http://holisticsecurity.io/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress){:target=&quot;_blank&quot;}.


### 2. Create a fresh K8s Cluster with JetStack Cert-Manager installed

Note the `cert-manager-enabled=&quot;1&quot;` and `cert-manager-email=&quot;cheapk8s@holisticsecurity.io&quot;` parameters which are required to create a Kubernetes Cluster with the [JetStack Cert-Manager](https://github.com/jetstack/cert-manager){:target=&quot;_blank&quot;} installed.

```sh
$ terraform plan \
  -var cluster-name=&quot;cheapk8s&quot; \
  -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
  -var admin-cidr-blocks=&quot;83.50.13.174/32&quot; \
  -var region=&quot;us-east-1&quot; \
  -var kubernetes-version=&quot;1.14.3&quot; \
  -var external-dns-enabled=&quot;1&quot; \
  -var nginx-ingress-enabled=&quot;1&quot; \
  -var nginx-ingress-domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; \
  -var cert-manager-enabled=&quot;1&quot; \
  -var cert-manager-email=&quot;cheapk8s@holisticsecurity.io&quot; 

$ terraform apply \
  -var cluster-name=&quot;cheapk8s&quot; \
  -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
  -var admin-cidr-blocks=&quot;83.50.13.174/32&quot; \
  -var region=&quot;us-east-1&quot; \
  -var kubernetes-version=&quot;1.14.3&quot; \
  -var external-dns-enabled=&quot;1&quot; \
  -var nginx-ingress-enabled=&quot;1&quot; \
  -var nginx-ingress-domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; \
  -var cert-manager-enabled=&quot;1&quot; \
  -var cert-manager-email=&quot;cheapk8s@holisticsecurity.io&quot; 
```

### 3. Checking recently created K8s Cluster and JetStack Cert-Manager

**1. Exploring the JetStack Cert-Manager resources created in the K8s Cluster**

```sh
# Get SSH access to K8s master node
$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem

# List all namespaces
$ kubectl get ns
NAME              STATUS   AGE
cert-manager      Active   159m
default           Active   161m
ingress-nginx     Active   158m
kube-node-lease   Active   161m
kube-public       Active   161m
kube-system       Active   161m

# Listing all resources under namespace 'cert-manager'
$ kubectl get all -n cert-manager
NAME                                READY   STATUS    RESTARTS   AGE
pod/cert-manager-54d94bb6fc-9zchz   1/1     Running   0          5h22m

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/cert-manager   1/1     1            1           5h22m

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/cert-manager-54d94bb6fc   1         1         1       5h22m
```


**2. Calling Ingress' `health check` over TLS.**

```sh
$ curl https://ingress-nginx.cloud.holisticsecurity.io/healthz -v -k
[...]
&lt; HTTP/2 200 
&lt; server: nginx/1.15.5
&lt; date: Tue, 28 Jan 2020 15:23:26 GMT
&lt; content-type: text/html
&lt; content-length: 0
&lt; 
* Connection #0 to host ingress-nginx.cloud.holisticsecurity.io left intact
```

**3. Getting the TLS Certificate using `openssl`**

```sh
$ echo | openssl s_client -showcerts -servername ingress-nginx.cloud.holisticsecurity.io -connect ingress-nginx.cloud.holisticsecurity.io:443 2&gt;/dev/null | openssl x509 -inform pem -noout -text
```

### 4. Calling a Microservice over HTTPS (port 443)

Since all Microservices and RESTful API were configured to be invoked over 80/HTTP and 443/HTTPS and routed through the NGINX Ingress Controller. The only thing to do is call them through their FQDN (Fully Qualified Domain Name) and the Microservices' FQDN could be `https://ingress-nginx.cloud.holisticsecurity.io/&lt;MICROSERVICE_NAME&gt;`.

Then, let's try it using the `Hello Microservice`.

```sh
# Get SSH access to K8s master node
$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem
   
# Deploy Hello microservices, services and ingress
$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-app.yaml
$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-svc.yaml
$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-ingress.yaml
$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-ingress-tls.yaml
   
# Get status
$ kubectl get pod,svc,ingress -n hello -o wide
[...]
NAME                                       HOSTS                                     ADDRESS   PORTS     AGE
ingress.extensions/hello-ingress-cip       ingress-nginx.cloud.holisticsecurity.io             80        16m
ingress.extensions/hello-ingress-cip-tls   ingress-nginx.cloud.holisticsecurity.io             80, 443   15s
ingress.extensions/hello-ingress-np        hello-svc-np.cloud.holisticsecurity.io              80        16m
ingress.extensions/hello-ingress-np-tls    hello-svc-np.cloud.holisticsecurity.io              80, 443   15s
```

Now, from any computer in Internet execute this command:

```sh
# Calling Hello Microservices over HTTP
$ curl http://ingress-nginx.cloud.holisticsecurity.io/hello
$ curl http://hello-svc-np.cloud.holisticsecurity.io/hello 

# Calling Hello Microservices over HTTPS/TLS through `hello-ingress-cip-tls`
$ curl https://ingress-nginx.cloud.holisticsecurity.io/hello -v -k
[...]
Hello version: v1, instance: hello-v1-66fc9c7d98-tljkw
* Connection #0 to host ingress-nginx.cloud.holisticsecurity.io left intact

# Calling Hello Microservices over HTTPS/TLS through `hello-ingress-np-tls`
$ curl https://hello-svc-np.cloud.holisticsecurity.io/hello -v -k
[...]
Hello version: v2, instance: hello-v2-845749f774-tft56
* Connection #0 to host hello-svc-np.cloud.holisticsecurity.io left intact

```

## Conclusions

1. NGINX Ingress Controller routes HTTP and HTTPS/TLS traffic to Hello Microservices.
2. NGINX Ingress Controller manages TLS Termination, that means that Hello Microservices don't require X.509 TLS Certificate. In other words, the NGINX Ingress Controller redirect the ingress traffic to downstream microservice over HTTP standard.
3. Hello Microservices are exposed through NGINX Ingress enabling TLS and requesting X.509 TLS Certificate. Note the `annotations` used in the `Ingress Resource` definition. Below details:

```yaml
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: hello-ingress-cip-tls
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    certmanager.k8s.io/issuer: &quot;letsencrypt-prod&quot;
    certmanager.k8s.io/acme-challenge-type: http01
  namespace: hello
spec:
  tls:
  - hosts:
    - ingress-nginx.cloud.holisticsecurity.io
    secretName: ingress-nginx-cloud-holisticsecurity-io-https
  rules:
  - host: ingress-nginx.cloud.holisticsecurity.io
    http:
      paths:
      - path: /
        backend:
          serviceName: hello-svc-cip
          servicePort: 5080
---
```

In the next post I'll explain how to enable Mutual TLS Authentication for Microservices.
Stay tuned.

## References

1. [JetStack Cert Manager - x.509 Certs for Kubernetes](https://github.com/jetstack/cert-manager){:target=&quot;_blank&quot;}
2. [Part 1 - Building your own affordable K8s to host a Service Mesh](http://holisticsecurity.io/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane){:target=&quot;_blank&quot;}.
3. [Part 2 - Building your own affordable K8s - ExternalDNS and NGINX as Ingress](http://holisticsecurity.io/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress){:target=&quot;_blank&quot;}.</content><author><name></name></author><category term="aws" /><category term="docker" /><category term="kubernetes" /><category term="data plane" /><category term="microservice" /><category term="x509" /><category term="pki" /><summary type="html">In this blog post I’ll explain how to get a X.509 TLS Certificate from Let’s Encrypt automatically during the Terraform provision time, in this way we can now invoke the services additionally on port 443 (HTTPS/TLS). During the Terraform execution, immediately after Kubernetes Cluster creation, the JetStack Cert-Manager is deployed in a Pod, it is who will request to Let’s Encrypt service a X.509 TLS Certificate, once completed, the JetStack Cert-Manager will inject the X.509 Certificate as a Kubernetes Secret into NGINX Ingress Controller to enbale TLS. At this point you must have created a Kubernetes Cluster with ExternalDNS and NGINX as Ingress Controller. If you don’t know how to achieve that, I recommend to follow these posts: Part 1 - Building your own affordable K8s to host a Service Mesh. Part 2 - Building your own affordable K8s - ExternalDNS and NGINX as Ingress.</summary></entry><entry><title type="html">Building your own affordable K8s to host a Service Mesh - Part 2: External DNS and Ingress</title><link href="http://localhost:4000/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress" rel="alternate" type="text/html" title="Building your own affordable K8s to host a Service Mesh - Part 2: External DNS and Ingress" /><published>2020-01-22T10:00:00+01:00</published><updated>2020-01-22T10:00:00+01:00</updated><id>http://localhost:4000/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane-part2-external-dns-ingress</id><content type="html" xml:base="http://localhost:4000/2020/01/22/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-part2-external-dns-ingress">In order to get an affordable Kubernetes, every part we're going to use should be affordable too, and ones of the expensive and tricky things are the [AWS Elastic Load Balancing (ELB)](https://aws.amazon.com/elasticloadbalancing){:target=&quot;_blank&quot;} and the [AWS Route 53 (DNS)](https://aws.amazon.com/route53){:target=&quot;_blank&quot;}. Fortunately, Kubernetes SIGs are working to address this gap with the [Kubernetes ExternalDNS](https://github.com/kubernetes-sigs/external-dns){:target=&quot;_blank&quot;}.

**But what is the problem?**

Apart of it is expensive, the problem is every time I deploy a `Service` in Kubernetes I have to update and add a new DNS entry in the Cloud Provider's DNS manually. Yes, of course, the process can be automated, but the idea is doing it during the provisioning time. In other words, every developer can publish theirs services adding the DNS name as annotation for that services can be called over Internet.
Yes, [Kubernetes brings by default a DNS](https://github.com/kubernetes/dns){:target=&quot;_blank&quot;} but this is an internal one and it is only to work resolving DNS names over the Kubernetes Network, not for internet facing services.

**The Solution**

The Kubernetes ExternalDNS will run a program in our affordable K8s which it will synchronize exposed Kubernetes Services and Ingresses with the Cloud Provider's DNS Service, in this case with AWS Route 53. Below you can view a high level diagram and current status of my [Affordable Kubernetes Data Plane, I recommend look at first post about it](http://holisticsecurity.io/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane){:target=&quot;_blank&quot;}.

[![Service Mesh hosted using AWS Spot Instances](/assets/img/20200122-service-mesh-01-affordablek8s-aws-arch.png &quot;Service Mesh using AWS Spot Instances&quot;)](/assets/img/20200122-service-mesh-01-affordablek8s-aws-arch.png){:target=&quot;_blank&quot;}

&lt;!-- more --&gt;

Then, let's do it.

## Steps

### 1. Create a Hosted Zone in AWS Route 53

I'm going to register the subdomain `cloud.holisticsecurity.io` of existing Root domain name `holisticsecurity.io` into AWS Route 53. I'll follow the below AWS Route 53 explanation.

* [Using Amazon Route 53 as the DNS Service for Subdomains Without Migrating the Parent Domain](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/creating-migrating.html){:target=&quot;_blank&quot;}

You can create subdomain records using either the Amazon Route 53 console or the Route 53 API. Since I have already `AWS CLI` configured in my PC, then let's use it.

**1) Create a Hosted Zone in AWS 53 for the Subdomain**

```sh
# Create a DNS zone which will contain the managed DNS records.
$ aws route53 create-hosted-zone --name &quot;cloud.holisticsecurity.io.&quot; --caller-reference &quot;cloud-holosec-io-$(date +%s)&quot; --hosted-zone-config &quot;Comment='HostedZone for subdomain',PrivateZone=false&quot;

# Get the Hosted Zone ID (HZ_ID) of the hosted zone I just created, which will serve as the value for my-hostedzone-identifier.
$ export HZ_ID=$(aws route53 list-hosted-zones-by-name --output json --dns-name &quot;cloud.holisticsecurity.io.&quot; | jq -r '.HostedZones[0].Id')

# Make a note of the nameservers that were assigned to my new zone.
$ aws route53 list-resource-record-sets --output json --hosted-zone-id &quot;${HZ_ID}&quot; --query &quot;ResourceRecordSets[?Type == 'NS']&quot; | jq -r '.[0].ResourceRecords[].Value'
ns-1954.awsdns-52.co.uk.
ns-157.awsdns-19.com.
ns-1053.awsdns-03.org.
ns-789.awsdns-34.net.
```

**2) Add `Name Server Records` for the specified Subdomain in the DNS Service Provider Console**

 After changes to Amazon Route 53 records have propagated, the next step is to update the DNS service for the parent domain by adding `NS` type records for the specified subdomain. This is known as delegating responsibility for the subdomain to Route 53. 

I will need the above four nameserver that I got querying with `AWSCLI`. Note that those nameservers are for my subdomain, likely you got others.

```
ns-1954.awsdns-52.co.uk.
ns-157.awsdns-19.com.
ns-1053.awsdns-03.org.
ns-789.awsdns-34.net.
```
Finally, for my subdomain `cloud.holisticsecurity.io`, you should have as shown below:

```
[...]
cloud 1800 IN NS ns-1053.awsdns-03.org.
cloud 1800 IN NS ns-157.awsdns-19.com.
cloud 1800 IN NS ns-1954.awsdns-52.co.uk.
cloud 1800 IN NS ns-789.awsdns-34.net.
[...]
```

Ah, also you should wait some minutes or hours to propagate these changes. That depends on your DNS Service Provider.


### 2. Provision of Kubernetes Cluster with ExternalDNS through Terraform


If you have read the first post about how to create an affordable Kubernetes Data Plane, then you will know that I used Terraform to provision it. I'm using the [Really cheap Kubernetes cluster on AWS with kubeadm](https://github.com/cablespaghetti/kubeadm-aws){:target=&quot;_blank&quot;} Guide's [Sam Weston](https://cablespaghetti.github.io){:target=&quot;_blank&quot;} which already uses Kubernetes ExternalDNS, then I'm going to re-apply the Terraform scripts activating the installation of ExternalDNS.


**1) Create a fresh affordable Kubernetes Cluster**

1. Clone the Affordable K8s Cluster Github repo

   &gt; If you want a cheap K8s Infrastructure on AWS, I recommend to clone this GitHub repo I've updated for you.
   &gt;  
   &gt; [https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano](https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano){:target=&quot;_blank&quot;}
   &gt;  
   
   Once cloned, first of all run `terraform destroy` to remove all AWS resources provisioned previously. TThat will avoid increasing your bill.
   After cleaning up, reprovision a fresh Kubernetes Cluster.
   
   ```sh
   $ terraform plan \
     -var cluster-name=&quot;cheapk8s&quot; \
     -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
     -var admin-cidr-blocks=&quot;83.50.9.220/32&quot; \
     -var region=&quot;us-east-1&quot; \
     -var kubernetes-version=&quot;1.14.3&quot; \
     -var external-dns-enabled=&quot;1&quot; \
     -var nginx-ingress-enabled=&quot;1&quot; \
     -var nginx-ingress-domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; 
   
   $ terraform apply \
     -var cluster-name=&quot;cheapk8s&quot; \
     -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
     -var admin-cidr-blocks=&quot;83.50.9.220/32&quot; \
     -var region=&quot;us-east-1&quot; \
     -var kubernetes-version=&quot;1.14.3&quot; \
     -var external-dns-enabled=&quot;1&quot; \
     -var nginx-ingress-enabled=&quot;1&quot; \
     -var nginx-ingress-domain=&quot;ingress-nginx.cloud.holisticsecurity.io&quot; 
   ```

2. Clean up unwanted Name Server Records under the AWS Route 53 Hosted Zone for the specified Subdomain.

   If you have been playing with AWS Route 53 Hosted Zone for the specified Subdomain (`cloud.holisticsecurity.io`), it's likely you have added records and require removing them before creating fresh records. Then, below I explain you how to do:
   
   ```sh
   # A fresh AWS Route 53 Hosted Zone has 2 records: Record Type NS and Record Type SOA.
   $ export MY_SUBDOMAIN=&quot;cloud.holisticsecurity.io&quot;
   $ export HZ_ID=$(aws route53 list-hosted-zones-by-name --dns-name &quot;${MY_SUBDOMAIN}.&quot; | jq -r '.HostedZones[0].Id')
   $ aws route53 list-resource-record-sets --hosted-zone-id $HZ_ID --query &quot;ResourceRecordSets[?Name == '${MY_SUBDOMAIN}.'].{Name:Name,Type:Type}&quot; | jq -c '.[]'
   {&quot;Name&quot;:&quot;cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;NS&quot;}
   {&quot;Name&quot;:&quot;cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;SOA&quot;}
   
   # I should remove those 10 records (of type A, TXT and SRV) 
   $ aws route53 list-resource-record-sets --hosted-zone-id $HZ_ID --query &quot;ResourceRecordSets[?Name != '${MY_SUBDOMAIN}.'].{Name:Name,Type:Type}&quot; | jq -c '.[]'
   {&quot;Name&quot;:&quot;hello-svc-np.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;A&quot;}
   {&quot;Name&quot;:&quot;hello-svc-np.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;TXT&quot;}
   {&quot;Name&quot;:&quot;_http._tcp.hello-svc-np.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;SRV&quot;}
   {&quot;Name&quot;:&quot;_http._tcp.hello-svc-np.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;TXT&quot;}
   {&quot;Name&quot;:&quot;ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;A&quot;}
   {&quot;Name&quot;:&quot;ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;TXT&quot;}
   {&quot;Name&quot;:&quot;_http._tcp.ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;SRV&quot;}
   {&quot;Name&quot;:&quot;_http._tcp.ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;TXT&quot;}
   {&quot;Name&quot;:&quot;_https._tcp.ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;SRV&quot;}
   {&quot;Name&quot;:&quot;_https._tcp.ingress-nginx.cloud.holisticsecurity.io.&quot;,&quot;Type&quot;:&quot;TXT&quot;}
   
   # Removing those unwanted records.
   $ aws route53 list-resource-record-sets --hosted-zone-id $HZ_ID --query &quot;ResourceRecordSets[?Name != '${MY_SUBDOMAIN}.']&quot; | jq -c '.[]' |
     while read -r RRS; do
       read -r name type &lt;&lt;&lt; $(jq -jr '.Name, &quot; &quot;, .Type' &lt;&lt;&lt; &quot;$RRS&quot;) 
       CHG_ID=$(aws route53 change-resource-record-sets --hosted-zone-id $HZ_ID --change-batch '{&quot;Changes&quot;:[{&quot;Action&quot;:&quot;DELETE&quot;,&quot;ResourceRecordSet&quot;: '&quot;$RRS&quot;' }]}' --output text --query 'ChangeInfo.Id')
       echo &quot; - DELETING: $type $name - CHANGE ID: $CHG_ID&quot;    
     done
   
    - DELETING: TXT ccc.cloud.holisticsecurity.io. - CHANGE ID: /change/CMCJ8CXRBIZ7M
    - DELETING: SRV ddd.cloud.holisticsecurity.io. - CHANGE ID: /change/C2KU4TEHWEDV2Y
   ```
   
   Only if it is required, you can delete the AWS Hosted Zone in this way:
   ```sh
   $ aws route53 delete-hosted-zone --id $HZ_ID --output text --query 'ChangeInfo.Id'
   ```

**2) Verify ExternalDNS has synchronized the Ingress' subdomain with AWS Route 53**

The domain name that the Ingress' subdomain will request is `ingress-nginx.cloud.holisticsecurity.io`, that domain name has been created during the Affordable K8s Cluster creation. Then, let's check it.

```sh
$ export MY_SUBDOMAIN=&quot;cloud.holisticsecurity.io&quot;
$ export INGRESS_NS=&quot;ingress-nginx.${MY_SUBDOMAIN}&quot;

# Get the Hosted Zone (HZ_ID) ID of the hosted zone I just created.
$ export HZ_ID=$(aws route53 list-hosted-zones-by-name --dns-name &quot;${MY_SUBDOMAIN}.&quot; | jq -r '.HostedZones[0].Id')

# Get all nameservers that were assigned initially and recently synchronized by ExternalDNS to my new zone.
$ aws route53 list-resource-record-sets --output text --hosted-zone-id &quot;${HZ_ID}&quot; --query &quot;ResourceRecordSets[?Name == '${INGRESS_NS}.'].{Name:Name,Type:Type}&quot;

ingress-nginx.cloud.holisticsecurity.io.	A
ingress-nginx.cloud.holisticsecurity.io.	TXT
```

Or if you are of the old-school, you can ask to any of four AWS Route 53's DNS server if the subdomain has been created and updated.

```sh
$ dig +short @ns-1954.awsdns-52.co.uk. ingress-nginx.cloud.holisticsecurity.io.
174.129.123.159
54.159.75.179

$ dig +short @ns-157.awsdns-19.com. ingress-nginx.cloud.holisticsecurity.io.
174.129.123.159
54.159.75.179

$ dig +short @ns-1053.awsdns-03.org. ingress-nginx.cloud.holisticsecurity.io.
174.129.123.159
54.159.75.179

$ dig +short @ns-789.awsdns-34.net. ingress-nginx.cloud.holisticsecurity.io.
174.129.123.159
54.159.75.179
```

Both above IP addresses are the `IPv4 Public IP` addresses assigned to Kubernetes Master Node and Kubernetes Worker Node. If I add a new Node to existing Kubernetes Cluster, the `NGINX Ingress Controller` will be installed in the new Node and its new `IPv4 Public IP` address will resolve to `ingress-nginx.cloud.holisticsecurity.io`, that is why the `NGINX Ingress Controller` was deployed into Kubernetes as a [`DaemonSet`](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/){:target=&quot;_blank&quot;}. Let's to verify it.


```sh
# Get SSH access to K8s master node
$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem

ubuntu@ip-10-0-100-4:~$ kubectl get daemonset -n ingress-nginx
NAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
nginx-ingress-controller   2         2         2       2            2           &lt;none&gt;          14h

ubuntu@ip-10-0-100-4:~$ kubectl get pods -n ingress-nginx -o wide
NAME                                    READY   STATUS    RESTARTS   AGE   IP            NODE                          NOMINATED NODE   READINESS GATES
default-http-backend-5c9bb94849-pf5pj   1/1     Running   0          14h   10.244.1.3    ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
nginx-ingress-controller-bwhdp          1/1     Running   0          14h   10.0.100.22   ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
nginx-ingress-controller-q4bgh          1/1     Running   0          14h   10.0.100.4    ip-10-0-100-4.ec2.internal    &lt;none&gt;           &lt;none&gt;
```

**3) Verify ExternalDNS and NGINX Ingress work together (Health Check example)**


Since the `CheapK8s` only exposes RESTful services over `80` and `443` ports, then to verify that I need to call the `Health Check` service of my [NGINX Ingress Controller](https://github.com/chilcano/kubeadm-aws/blob/0.2.1-chilcano/manifests/nginx-ingress-mandatory.yaml){:target=&quot;_blank&quot;} deployed through Terraform in previous step. This procedure also verify that the `NGINX Ingress Controller` has got a DNS name (subdomain `ingress-nginx.cloud.holisticsecurity.io`) from `ExternalDNS` successfully. This part has been configured in the file [`manifests/nginx-ingress-nodeport.yaml.tmpl`](https://github.com/chilcano/kubeadm-aws/blob/0.2.1-chilcano/manifests/nginx-ingress-nodeport.yaml.tmpl){:target=&quot;_blank&quot;}.


```sh
$ curl -X GET http://ingress-nginx.cloud.holisticsecurity.io/healthz -v

Note: Unnecessary use of -X or --request, GET is already inferred.
*   Trying 174.129.123.159:80...
* TCP_NODELAY set
* Connected to ingress-nginx.cloud.holisticsecurity.io (174.129.123.159) port 80 (#0)
&gt; GET /healthz HTTP/1.1
&gt; Host: ingress-nginx.cloud.holisticsecurity.io
&gt; User-Agent: curl/7.65.3
&gt; Accept: */*
&gt; 
* Mark bundle as not supporting multiuse
&lt; HTTP/1.1 200 OK
&lt; Server: nginx/1.15.5
&lt; Date: Tue, 21 Jan 2020 21:24:45 GMT
&lt; Content-Type: text/html
&lt; Content-Length: 0
&lt; Connection: keep-alive
&lt; 
* Connection #0 to host ingress-nginx.cloud.holisticsecurity.io left intact
```

**4) Verify ExternalDNS and NGINX Ingress work together (Service example)**


1. Deploy Hello Microservice and check the deployment status

   ```sh
   # Get SSH access to K8s master node
   $ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem
   
   # Deploy Hello microservices
   ubuntu@ip-10-0-100-4:~$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-app.yaml
   namespace/hello created
   serviceaccount/hello-sa created
   deployment.extensions/hello-v1 created
   deployment.extensions/hello-v2 created
   
   # Create ClusterIP, LoadBalancer and NodePort Services for above Hello microservices
   ubuntu@ip-10-0-100-4:~$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-svc.yaml
   service/hello-svc-cip created
   service/hello-svc-lb created
   service/hello-svc-np created
   
   # Create 2 Ingress Resources for above ClusterIP and NodePort Services
   ubuntu@ip-10-0-100-4:~$ kubectl apply -f https://raw.githubusercontent.com/chilcano/kubeadm-aws/0.2.1-chilcano/examples/hello-cheapk8s-ingress.yaml
   ingress.extensions/hello-ingress-cip created
   ingress.extensions/hello-ingress-np created
   
   # Get status
   ubuntu@ip-10-0-100-4:~$ kubectl get pod,svc,ingress -n hello -o wide
   NAME                            READY   STATUS    RESTARTS   AGE   IP            NODE                          NOMINATED NODE   READINESS GATES
   pod/hello-v1-66fc9c7d98-7b4b5   1/1     Running   0          32m   10.244.1.16   ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
   pod/hello-v1-66fc9c7d98-kb2kn   1/1     Running   0          32m   10.244.1.17   ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
   pod/hello-v2-845749f774-fzg5f   1/1     Running   0          32m   10.244.1.18   ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
   pod/hello-v2-845749f774-q9bk5   1/1     Running   0          31m   10.244.1.19   ip-10-0-100-22.ec2.internal   &lt;none&gt;           &lt;none&gt;
   
   NAME                    TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE   SELECTOR
   service/hello-svc-cip   ClusterIP      10.108.175.6    &lt;none&gt;        5080/TCP         22m   app=hello
   service/hello-svc-lb    LoadBalancer   10.102.10.180   &lt;pending&gt;     5080:32379/TCP   22m   app=hello
   service/hello-svc-np    NodePort       10.105.22.106   &lt;none&gt;        5080:31002/TCP   22m   app=hello
   
   NAME                                   HOSTS                                     ADDRESS   PORTS   AGE
   ingress.extensions/hello-ingress-cip   ingress-nginx.cloud.holisticsecurity.io             80      17m
   ingress.extensions/hello-ingress-np    hello-svc-np.cloud.holisticsecurity.io              80      17m
   ```

2. Understanding how works microservice exposition and how they should be called

   Since the `ExternalDNS` and `NGINX Ingress Controller` have been configured in the `CheapK8s` Cluster, the only way to call the [Hello Microservices](https://github.com/chilcano/kubeadm-aws/blob/0.2.1-chilcano/examples/hello-cheapk8s-app.yaml){:target=&quot;_blank&quot;} is through their [`Ingress Resources`](https://github.com/chilcano/kubeadm-aws/blob/0.2.1-chilcano/examples/hello-cheapk8s-ingress.yaml){:target=&quot;_blank&quot;} and their [`Services`](https://github.com/chilcano/kubeadm-aws/blob/0.2.1-chilcano/examples/hello-cheapk8s-svc.yaml){:target=&quot;_blank&quot;}.
   
   It is very important to understand how Kubernetes exposes our microservices. Next, I copy some concepts (Kubernetes' primitives) and references to understand the whole operation.
   
   &gt;  
   &gt; * `ClusterIP`: Exposes the Service on a cluster-internal IP. Choosing this value makes the Service only reachable from within the cluster. This is the default `ServiceType`.
   &gt; * `LoadBalancer`: Exposes the Service externally using a cloud provider’s load balancer. `NodePort` and `ClusterIP` Services, to which the external load balancer routes, are automatically created.
   &gt; * `NodePort`: Exposes the Service on each Node’s IP at a static port (the `NodePort`). A `ClusterIP` Service, to which the `NodePort` Service routes, is automatically created. You’ll be able to contact the `NodePort` Service, from outside the cluster, by requesting `&lt;NodeIP&gt;:&lt;NodePort&gt;`.
   &gt;  
   &gt; Info: [Kubernetes - Publishing Services (ServiceTypes)](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types){:target=&quot;_blank&quot;}
   &gt;  
   
   And this is my favorite one.
   &gt; 
   &gt; [The Hardest Part of Microservices: Calling Your Services by Christian Posta, 2017/April/25](https://blog.christianposta.com/microservices/the-hardest-part-of-microservices-calling-your-services){:target=&quot;_blank&quot;}
   &gt;  
   
3. Calling Hello Microservices

   
   Calling through Services (ClusterIP, LoadBalancer and NodePort) from inside of Kubernetes Cluster. Although below I'm using `ClusterIP`, you can repeat similar process using the `LoadBalancer` and `NodePort`.
   
   ```sh
   $ kubectl get svc/hello-svc-cip -o jsonpath='{.spec.clusterIP}'
   $ kubectl get svc/hello-svc-cip -o jsonpath='{.spec.ports[0].port}'
   $ export HELLO_SVC_CIP=$(kubectl get svc/hello-svc-cip -n hello -o jsonpath='{.spec.clusterIP}'):$(kubectl get svc/hello-svc-cip -n hello -o jsonpath='{.spec.ports[0].port}')
   $ echo $HELLO_SVC_CIP
   
   $ curl http://${HELLO_SVC_CIP}/hello
   Hello version: v1, instance: hello-v1-5cb886df9d-k7rcq
   
   $ curl http://${HELLO_SVC_CIP}/hello
   Hello version: v2, instance: hello-v2-6c7fbbb654-kq6sq
   
   $ curl http://${HELLO_SVC_CIP}/hello
   Hello version: v1, instance: hello-v1-5cb886df9d-k7rcq
   
   $ kubectl logs -f -l app=hello -n hello
    * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
    * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
   10.244.0.0 - - [22/Jan/2020 11:20:45] &quot;GET /hello HTTP/1.1&quot; 200 -
   10.244.0.0 - - [22/Jan/2020 11:22:27] &quot;GET /hello HTTP/1.1&quot; 200 -
   10.244.0.0 - - [22/Jan/2020 11:22:33] &quot;GET /hello HTTP/1.1&quot; 200 -
   ```
   
   Calling from Internet through Kubernetes Ingress Controller and its Fully Qualified Domain Name (`FQDN`).
   
   ```sh
   $ curl http://ingress-nginx.cloud.holisticsecurity.io/hello
   Hello version: v2, instance: hello-v2-845749f774-q9bk5
   
   $ curl http://hello-svc-np.cloud.holisticsecurity.io/hello
   Hello version: v1, instance: hello-v1-66fc9c7d98-7b4b5
   ```

## References

1. [Kubernetes SIGs ExternalDNS's github repo](https://github.com/kubernetes-sigs/external-dns){:target=&quot;_blank&quot;}
2. [The missing piece - Kubernetes ExternalDNS by Lachlan Evenson, 2017/Aug/09](https://www.youtube.com/watch?v=9HQ2XgL9YVI){:target=&quot;_blank&quot;}
3. [The NGINX Ingress Controller](https://github.com/kubernetes/ingress-nginx){:target=&quot;_blank&quot;}
4. [Kubernetes concepts - Service](https://kubernetes.io/docs/concepts/services-networking/service/){:target=&quot;_blank&quot;}
5. [Kubernetes concepts - Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/){:target=&quot;_blank&quot;}
6. [The Hardest Part of Microservices: Calling Your Services by Christian Posta, 2017/April/25](https://blog.christianposta.com/microservices/the-hardest-part-of-microservices-calling-your-services){:target=&quot;_blank&quot;}

In the next blog post I'll explain how to generate TLS Certificates for your Microservices.
Stay tuned.</content><author><name></name></author><category term="aws" /><category term="docker" /><category term="kubernetes" /><category term="data plane" /><category term="microservice" /><category term="external dns" /><category term="ingress" /><category term="nginx" /><summary type="html">In order to get an affordable Kubernetes, every part we’re going to use should be affordable too, and ones of the expensive and tricky things are the AWS Elastic Load Balancing (ELB) and the AWS Route 53 (DNS). Fortunately, Kubernetes SIGs are working to address this gap with the Kubernetes ExternalDNS. But what is the problem? Apart of it is expensive, the problem is every time I deploy a Service in Kubernetes I have to update and add a new DNS entry in the Cloud Provider’s DNS manually. Yes, of course, the process can be automated, but the idea is doing it during the provisioning time. In other words, every developer can publish theirs services adding the DNS name as annotation for that services can be called over Internet. Yes, Kubernetes brings by default a DNS but this is an internal one and it is only to work resolving DNS names over the Kubernetes Network, not for internet facing services. The Solution The Kubernetes ExternalDNS will run a program in our affordable K8s which it will synchronize exposed Kubernetes Services and Ingresses with the Cloud Provider’s DNS Service, in this case with AWS Route 53. Below you can view a high level diagram and current status of my Affordable Kubernetes Data Plane, I recommend look at first post about it.</summary></entry><entry><title type="html">Building your own affordable K8s to host a Service Mesh - Part 1</title><link href="http://localhost:4000/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane" rel="alternate" type="text/html" title="Building your own affordable K8s to host a Service Mesh - Part 1" /><published>2020-01-16T10:00:00+01:00</published><updated>2020-01-16T10:00:00+01:00</updated><id>http://localhost:4000/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane</id><content type="html" xml:base="http://localhost:4000/2020/01/16/building-your-own-affordable-cloud-k8s-to-host-a-service-mesh-data-plane">I want to build a Container-based Cloud to deploy any kind of workload (RESTful API, Microservices, Event-Driven, Functions, etc.) but it should be affordable, ready to use, reliable, secure and productionable. This means:

- Productionable: should be fully functional and ready to be used as a production environment.
- Reliable and Secure: able to improve the security level by implementing more security controls, at least fully isolated secure private networking.
- Affordable: cheaper.
- Ready to use: able to be automated (DevOps and IaC) with a mature management API.

Below a high level architecture of Container-based Cloud I want to get. I will focus on the Service Mesh Data Plane.  
[![](/assets/img/20200116-service-mesh-01-reference-arch-2.png &quot;Service Mesh hosted in a Container-based Cloud&quot;)](/assets/img/20200116-service-mesh-01-reference-arch-2.png){:target=&quot;_blank&quot;}

These requeriments restric some options, all of them using any Public Cloud Provider, but considering the [AWS Spot Instances](https://aws.amazon.com/ec2/spot) and [Google Cloud Preemptible VM Instances](https://cloud.google.com/preemptible-vms). Unfortunately Microsoft Azure only provides Low-Priority VMs to be used from Azure Batch Service. But if you are new user, you could apply for using the Free Tier in all of 3 Cloud Providers. 

&lt;!-- more --&gt;

For further information, you can read these articles:

* [Understanding Excess Cloud Capacity: Amazon EC2 Spot vs. Azure Low-Priority VM vs. Google Preemptible VM vs IBM Transient Servers](https://spotinst.com/blog/amazon-ec2-spot-vs-azure-lpvms-vs-google-pvms-vs-ibm-transient-servers/) - By Zev Schonberg, 2019-Mar
* [Cloud vendor free tiers compared: AWS vs Azure vs Google Cloud Platform](https://www.computerworld.com/article/3427685/cloud-vendor-free-tiers-compared--aws-vs-azure-vs-google-cloud-platform.html) - By Scott Carey, 2018-May

The automation can be achieved using Terraform, Python, Bash, etc. and the 2 Cloud Providers (AWS and Google Cloud) choosen for this project have a mature Management API which can be used to automatization and configuration.

## How much will the Kubernetes Cluster cost me?

Well, It is too difficult to know the cost exactly right now, however, I can estimate what it will cost me for a month. Below you can see two images, the first one is the High level AWS design and the next one is the approximate cost of the all AWS resources used during a month.

[![](/assets/img/20200122-service-mesh-01-affordablek8s-aws-arch.png &quot;Kubernetes Cluster using AWS Spot Instances&quot;)](/assets/img/20200122-service-mesh-01-affordablek8s-aws-arch.png){:target=&quot;_blank&quot;}

You can see below that my K8s Cluster using AWS Spot instances will cost approx. `6.79 Euros`, that includes:
* Instances EC2 Spot: 2
* Type: m1.small
* AZ: us-east-1
* S3 Storage 1GB
* S3 Put/Copy/Post / mo(K): 96
* S3 Get and other / mo(K): 2880
* Backup into S3 cron expression: &quot;*/15 * * * *&quot; 

[![](/assets/img/20200116-service-mesh-04-affordable-k8s-aws-budget.png &quot;K8s Cluster hosted using AWS Spot Instances - Cost&quot;)](/assets/img/20200116-service-mesh-04-affordable-k8s-aws-budget.png){:target=&quot;_blank&quot;}


## What about Digital Ocean, Hetzner Cloud, Scaleway and other Providers?

Yes, all of them are worthy of being considered too and will do it in next blog posts, but let's start with AWS and Google first. 
Ah, if you don't want to wait, I suggest you read the [Kubernetes clusters for the hobbyist](https://github.com/hobby-kube/guide) guide written by Patrick Stadler. This guide explains how to build a Kubernetes Cluster on [Digital Ocean](https://www.digitalocean.com), [Hetzner Cloud](https://www.hetzner.com/) and/or [Scaleway](https://www.scaleway.com), and this guide is accompanied by a fully automated cluster setup based on Terraform recipes. The guide suggests that [Linode](https://www.linode.com/), [Vultr](https://www.vultr.com) are other viable options. 

&gt;  
&gt; If you know a reliable, secure and affordable Cloud Provider, don't hesitate to drop me a line.
&gt;  

## Cheap doesn't mean unreliable, doesn't mean unsecure

Choose a cloud provider based on a few criteria such as trustworthiness, reliability, pricing and data center location is critical for this project. Security is a must, create a cluster in a private network doesn't mean it is secure. I will create multiple clusters to host different kind of workloads, then they should be isolated, implement secure private networking and implement Access Control (Authentication and Authorization).

## Let's do it

Then, in this post I will explain how to create an affordable Data Plane in AWS, to do that I'm going to use the [Really cheap Kubernetes cluster on AWS with kubeadm](https://github.com/cablespaghetti/kubeadm-aws) Guide's [Sam Weston](https://cablespaghetti.github.io) which will create a Kubernetes Cluster in AWS by using [AWS EC2 Spot Instances](https://aws.amazon.com/ec2/spot), [Terraform](https://www.terraform.io), Bash and [Helm](https://helm.sh) for automation, External DNS and Nginx Ingress as a cheap ELB alternative, and [Cert Manager](https://cert-manager.io) for TLS certificates via [Let's Encrypt](https://letsencrypt.org). Other features implemented are:

* Automatic backup and recovery.
* Auto Scaling of worker nodes. 
* Persistent Volumes using General Purpose SSD (GP2) storage on [AWS EBS](https://aws.amazon.com/ebs).

### Steps


**1) Terraform**


1. Download Terraform bundle.

   &gt; I've attempted to use Terraform 12.x, but unfortunately Terraform scrips need to be tweaked before, for that, for this blog post I recommend download and install [Terraform 11.15-oci](https://releases.hashicorp.com/terraform/) version.  
   &gt; The `oci` suffix means that Terraform is compatible with [Oracle Cloud Infrastructure](https://www.terraform.io/docs/providers/oci/guides/faq.html). 

2. Extract the downloaded `terraform` binary file and move it into a directory searched for executables.

   ```sh
   chilcano@inti:~$ unzip ~/Downloads/terraform_0.11.15-oci_linux_amd64.zip 
 
   chilcano@inti:~$ sudo mv terraform /usr/local/bin/
   
   chilcano@inti:~$ terraform -v
   Terraform v0.11.15-oci
   ```

**2) AWS (optional)**


Although AWS CLI isn't needed for the purpose of running Terraform, that will be useful in the next blog posts.

1. Install AWS CLI. It requires Pip 3.

   ```sh
   chilcano@inti:~$ pip3 --version
   pip 18.1 from /usr/lib/python3/dist-packages/pip (python 3.7)
   
   chilcano@inti:~$ pip3 install awscli --upgrade --user
   
   chilcano@inti:~$ aws --version
   aws-cli/1.16.314 Python/3.7.5 Linux/5.3.0-26-generic botocore/1.13.50
   
   chilcano@inti:~$ which aws
   /home/chilcano/.local/bin/aws
   ```

2. Configure the AWS account.

   ```sh
   chilcano@inti:~$ aws configure --profile affordablek8s01
   AWS Access Key ID [None]: &lt;ACCESS-KEY-ID&gt;
   AWS Secret Access Key [None]: &lt;SECRET-ACCESS-KEY&gt;
   Default region name [None]: us-west-2
   Default output format [None]: json
 
   chilcano@inti:~$ cat .aws/credentials 
   [affordablek8s01]
   aws_access_key_id = &lt;ACCESS-KEY-ID&gt;
   aws_secret_access_key = &lt;SECRET-ACCESS-KEY&gt;
   ```

3. Create a SSH key under the AZ where the resources will be created. In my case I'll create in `us-east-1` (Virginia) from the `AWS Web Console &gt; NETWORK &amp; SECURITY &gt; Key Pairs`. This SSH key will be used to get access to all nodes created in AWS for that specific AZ.


**3) Create the Kubernetes Cluster in AWS using Terraform**


1. Clone the Github repo.

   You can clone the [forked GitHub repo](https://github.com/chilcano/kubeadm-aws){:target=&quot;_blank&quot;} and switch to `0.2.1-chilcano` branch. 
   
   ```sh
   chilcano@inti:~/git-repos$ git clone https://github.com/chilcano/kubeadm-aws affordable-k8s-tf
   
   Cloning into 'affordable-k8s-tf'...
   remote: Enumerating objects: 327, done.
   remote: Total 327 (delta 0), reused 0 (delta 0), pack-reused 327
   Receiving objects: 100% (327/327), 71.68 KiB | 638.00 KiB/s, done.
   Resolving deltas: 100% (210/210), done.
   
   chilcano@inti:~/git-repos$ cd affordable-k8s-tf/
   
   chilcano@inti:~/git-repos/affordable-k8s-tf$ git tag -l
   0.1.0
   0.1.1
   0.1.2
   0.2.0
   0.2.1

   chilcano@inti:~/git-repos/affordable-k8s-tf$ git branch -a
   * master
     remotes/origin/0.2.1-chilcano
     remotes/origin/HEAD -&gt; origin/master
     remotes/origin/master

   chilcano@inti:~/git-repos/affordable-k8s-tf$ git branch -r
     origin/0.2.1-chilcano
     origin/HEAD -&gt; origin/master
     origin/master
   ```
   Now, let's switch to `0.2.1-chilcano` branch.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ git checkout 0.2.1-chilcano
   Branch '0.2.1-chilcano' set up to track remote branch '0.2.1-chilcano' from 'origin'.
   Switched to a new branch '0.2.1-chilcano'

   chilcano@inti:~/git-repos/affordable-k8s-tf$ git status
   On branch 0.2.1-chilcano
   Your branch is up to date with 'origin/0.2.1-chilcano'.
   
   nothing to commit, working tree clean
   ```
   
   &gt; Alternatively to all above steps you can clone the `0.2.1-chilcano` branch only of GitHub repo as follow:
   &gt; ```sh
   &gt; chilcano@inti:~/git-repos$ git clone --single-branch --branch 0.2.1-chilcano https://github.com/chilcano/kubeadm-aws affordable-k8s-tf
   &gt; ```

2. Update `variables.tf`.

   &gt; 
   &gt; Hard-coding any credentials into any Terraform configuration is not recommended. I recommend to provide your AWS credentials via `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables.
   &gt;  
   
   ```sh
   $ export AWS_ACCESS_KEY_ID=&quot;an-access-key&quot;
   $ export AWS_SECRET_ACCESS_KEY=&quot;a-secret-key&quot;
   ```
   
   In my case I'm not going to update any variables in `variables.tf`, I will overwrite them when running `terraform apply`. But if you want to do, the variables you have to modify are:
   
   * `cluster-name = &quot;MY-CHEAP-K8S&quot;`
   * `access_key = &quot;ENV-VAR-VALUE-WILL-BE-READ&quot;`
   * `secret_key = &quot;ENV-VAR-VALUE-WILL-BE-READ&quot;`
   * `k8s-ssh-key = &quot;SSH-KEY-NAME-CREATED-IN-AWS-CONSOLE&quot;`
   * `admin-cidr-blocks = &quot;YOUR-PUBLIC-IP-ADDRESS/32&quot;`
   * `region = &quot;us-east-1&quot;`
   * `master-instance-type = &quot;m1.small&quot;`
   * `worker-instance-type = &quot;m1.small&quot;`
   
   &gt; 
   &gt; If you change the `master-instance-type` and `worker-instance-type` values to `t2.micro` for example, that isn't going to work because the `t2.micro` AMIs are prepared to be autoscaled.
   &gt;  

3. Update `main.tf` and initialize the Terraform Providers.

   I will update `main.tf` to configure the 2 Terraform providers (`aws` and `random`) with proper versions according `Terraform v0.11.15-oci` version:
   
   ```terraform
   provider &quot;aws&quot; {
     #version    = &quot;~&gt; 1.48&quot;
     version    = &quot;~&gt; 2.44.0&quot;
     access_key = &quot;${var.access_key}&quot;
     secret_key = &quot;${var.secret_key}&quot;
     region     = &quot;${var.region}&quot;
   }
   
   provider &quot;template&quot; {
     version    = &quot;1.0.0&quot;
   }
   
   provider &quot;random&quot; {
     #version    = &quot;2.0.0&quot;
     version    = &quot;2.1.0&quot;
   }
   ```
   
   Now, initialize Terraform.
   
   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform init
   
   Initializing provider plugins...
   - Checking for available provider plugins on https://releases.hashicorp.com...
   - Downloading plugin for provider &quot;template&quot; (1.0.0)...
   - Downloading plugin for provider &quot;random&quot; (2.1.0)...
   - Downloading plugin for provider &quot;aws&quot; (2.44.0)...
   
   Terraform has been successfully initialized!
   
   You may now begin working with Terraform. Try running &quot;terraform plan&quot; to see
   any changes that are required for your infrastructure. All Terraform commands
   should now work.
   
   If you ever set or change modules or backend configuration for Terraform,
   rerun this command to reinitialize your working directory. If you forget, other
   commands will detect it and remind you to do so if necessary.
   ```

4. Get the Terraform Plan.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform plan \
     -var cluster-name=&quot;cheapk8s&quot; \
     -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
     -var admin-cidr-blocks=&quot;83.46.128.76/32&quot; \
     -var region=&quot;us-east-1&quot; \
     -var kubernetes-version=&quot;1.14.3&quot;
   
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform -v
   Terraform v0.11.15-oci
   + provider.aws v2.44.0
   + provider.random v2.1.0
   + provider.template v1.0.0
   
   Your version of Terraform is out of date! The latest version
   is 0.12.19. You can update by downloading from www.terraform.io/downloads.html
   ```

5. Visual exploration of the AWS resources are going to be created by Terraform.

   Terraform is able to export all Terraform scripts into a file in [DOT format](https://www.graphviz.org/doc/info/lang.html), useful to generate a graph through [GraphViz](http://www.graphviz.org). All details are explained here [&quot;Terraform - Command: graph&quot;](https://www.terraform.io/docs/commands/graph.html).
   
   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ sudo apt install graphviz
   terraform graph | dot -Tsvg &gt; your-graph.svg
   ```
   
   In my case I'm going to tweaking the DOT file to get a better graph. In fact, you can do it and once done, using an online service like this [Graphviz Online](https://dreampuf.github.io/GraphvizOnline) generate SVG file.
   
   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform graph -draw-cycles -module-depth=1 -type=apply &gt; 20200116-service-mesh-02-affordable-k8s-aws-graph.dot
   ```
   
   &gt; 
   &gt; You can download my updated DOT file from here [20200116-service-mesh-02-affordable-k8s-aws-graph.dot](/assets/img/20200116-service-mesh-02-affordable-k8s-aws-graph.dot).
   &gt; 

   [![Affordable K8s Data Plane hosted in AWS Graph](/assets/img/20200116-service-mesh-02-affordable-k8s-aws-graph.svg &quot;Affordable K8s Data Plane hosted in AWS Graph&quot;)](/assets/img/20200116-service-mesh-02-affordable-k8s-aws-graph.svg){:target=&quot;_blank&quot;}

6. Apply the Terraform Plan.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform apply \
     -var cluster-name=&quot;cheapk8s&quot; \
     -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
     -var admin-cidr-blocks=&quot;83.46.128.76/32&quot; \
     -var region=&quot;us-east-1&quot; \
     -var kubernetes-version=&quot;1.14.3&quot;
   ```
   
   And if you want to destroy all resources recently created by `terraform apply`, you can do it executing this:
   
   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ terraform destroy \
     -var cluster-name=&quot;cheapk8s&quot; \
     -var k8s-ssh-key=&quot;ssh-key-for-us-east-1&quot; \
     -var admin-cidr-blocks=&quot;83.46.128.76/32&quot; \
     -var region=&quot;us-east-1&quot; \
     -var kubernetes-version=&quot;1.14.3&quot;
   ```

**4) Check the Kubernetes Cluster**

If we want to check the Kubernetes Cluster creation, we have to review the `/var/log/cloud-init-output.log`. Before we should get remote access to Kubernetes Master host.

```sh
chilcano@inti:~/git-repos/affordable-k8s-tf$ chmod 400 ~/Downloads/ssh-key-for-us-east-1.pem
```

Now, getting remote access to Kubernetes Master host.

```sh
chilcano@inti:~/git-repos/affordable-k8s-tf$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem -- cat /var/log/cloud-init-output.log

[...]
Completed 1.0 KiB/1.0 KiB (6.9 KiB/s) with 1 file(s) remaining
upload: etc/kubernetes/pki/ca.crt to s3://cheapk8s20200115152212812700000001/pki/i-9343ae2e5c0e52dec/ca.crt
Completed 1.6 KiB/1.6 KiB (12.5 KiB/s) with 1 file(s) remaining
upload: etc/kubernetes/pki/ca.key to s3://cheapk8s20200115152212812700000001/pki/i-9343ae2e5c0e52dec/ca.key
Created symlink /etc/systemd/system/multi-user.target.wants/check-termination.service → /etc/systemd/system/check-termination.service.
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 running 'modules:final' at Wed, 15 Jan 2020 15:24:48 +0000. Up 81.04 seconds.
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 finished at Wed, 15 Jan 2020 15:33:22 +0000. Datasource DataSourceEc2Local.  Up 594.92 seconds
```

&gt;  
&gt; If you see above logs, that means that likely everything worked and Kubernetes Cluster was created successfully.
&gt; But, if you see below logs, that means Kubernetes Cluster wasn't created. In the below logs there are errors about Kubernetes packages (`kubeadm`, `kubelet` and `kubernetes-cni`) dependencies unmet when using `kubernetes-version=&quot;1.13.4&quot;` (default version of these Terraform scripts). To fix it we should change it to `kubernetes-version=&quot;1.14.3&quot;`.
&gt;  

```sh
ubuntu@ip-10-0-100-4:~$ cat /var/log/cloud-init-output.log

[...]
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
 kubeadm : Depends: kubernetes-cni (= 0.6.0) but 0.7.5-00 is to be installed
 kubelet : Depends: kubernetes-cni (= 0.6.0) but 0.7.5-00 is to be installed
E: Unable to correct problems, you have held broken packages.
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 running 'modules:final' at Wed, 15 Jan 2020 11:15:47 +0000. Up 88.84 seconds.
2020-01-15 11:16:17,468 - util.py[WARNING]: Failed running /var/lib/cloud/instance/scripts/part-001 [100]
2020-01-15 11:16:17,486 - cc_scripts_user.py[WARNING]: Failed to run module scripts-user (scripts in /var/lib/cloud/instance/scripts)
2020-01-15 11:16:17,486 - util.py[WARNING]: Running module scripts-user (&lt;module 'cloudinit.config.cc_scripts_user' from '/usr/lib/python3/dist-packages/cloudinit/config/cc_scripts_user.py'&gt;) failed
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 finished at Wed, 15 Jan 2020 11:16:18 +0000. Datasource DataSourceEc2Local.  Up 119.65 seconds
```

&gt;  
&gt; The below log shows other error related with incompatible `apiVersion` in `init-config.yaml` file created by `master.sh`. 
&gt; It shoud be changed to `apiVersion: kubeadm.k8s.io/v1beta1`.
&gt;  


```sh
ubuntu@ip-10-0-100-4:~$ cat /var/log/cloud-init-output.log

[...]
else
  echo &quot;Running kubeadm init&quot;
  kubeadm init --config=init-config.yaml --ignore-preflight-errors=NumCPU
  touch /tmp/fresh-cluster
fi
Running kubeadm init
your configuration file uses a deprecated API spec: &quot;kubeadm.k8s.io/v1alpha3&quot;. Please use 'kubeadm config migrate --old-config old.yaml --new-config new.yaml', which will write the new, similar spec using a newer API version.
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 running 'modules:final' at Wed, 15 Jan 2020 12:05:30 +0000. Up 78.18 seconds.
2020-01-15 12:10:10,299 - util.py[WARNING]: Failed running /var/lib/cloud/instance/scripts/part-001 [1]
2020-01-15 12:10:10,308 - cc_scripts_user.py[WARNING]: Failed to run module scripts-user (scripts in /var/lib/cloud/instance/scripts)
2020-01-15 12:10:10,308 - util.py[WARNING]: Running module scripts-user (&lt;module 'cloudinit.config.cc_scripts_user' from '/usr/lib/python3/dist-packages/cloudinit/config/cc_scripts_user.py'&gt;) failed
Cloud-init v. 19.3-41-gc4735dd3-0ubuntu1~18.04.1 finished at Wed, 15 Jan 2020 12:10:10 +0000. Datasource DataSourceEc2Local.  Up 357.91 seconds
```

**5) Access to Kubernetes Cluster**

If you want to know if your Kubernetes Cluster was created successfully, then you should do these checkings:

1. Check that there are no errors in `/var/log/cloud-init-output.log` log file.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem -- cat /var/log/cloud-init-output.log
   ```

2. Check that `kubelet` has started successfully.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem -- systemctl status kubelet
   ```

3. Finally, ask to Kubernetes to show all Cluster Nodes and its status.

   ```sh
   chilcano@inti:~/git-repos/affordable-k8s-tf$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem -- kubectl get nodes
   
   NAME                           STATUS   ROLES    AGE   VERSION
   ip-10-0-100-154.ec2.internal   Ready    &lt;none&gt;   48m   v1.14.3
   ip-10-0-100-4.ec2.internal     Ready    master   49m   v1.14.3

   chilcano@inti:~/git-repos/affordable-k8s-tf$ ssh ubuntu@$(terraform output master_dns) -i ~/Downloads/ssh-key-for-us-east-1.pem -- kubectl cluster-info
   Kubernetes master is running at https://10.0.100.4:6443
   KubeDNS is running at https://10.0.100.4:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
   ```
   
   ![Affordable K8s Data Plane hosted in AWS](/assets/img/20200116-service-mesh-03-affordable-k8s-aws.png &quot;Affordable K8s Data Plane hosted in AWS&quot;)
   
   &gt; 
   &gt; If you want a cheap K8s Infrastructure on AWS, I recommend to use this GitHub repo I've updated for you, once cloned just follow the above steps.
   &gt;  
   &gt; [https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano](https://github.com/chilcano/kubeadm-aws/tree/0.2.1-chilcano)
   &gt;  
   
   Below I've selected a set of good references to read related to this article and that will surely interest you.
   I hope this helps.


## References

- [Kubernetes: The Surprisingly Affordable Platform for Personal Projects](https://www.doxsey.net/blog/kubernetes--the-surprisingly-affordable-platform-for-personal-projects) By Caleb Doxsey - Sep 30, 2018
- [Affordable Kubernetes Cluster](https://devonblog.com/containers/affordable-kubernetes-cluster/) By Remko Seelig - March 12, 2019
- [Kubernetes clusters for the hobbyist](https://github.com/hobby-kube/guide) By Patrick Stadler - Latest commit on Oct 11, 2019
- [Kubernetes on the cheap](https://software.danielwatrous.com/kubernetes-on-the-cheap/) By Daniel Watrous - Feb 9, 2019
- [Kubernetes for poor - How to run your cluster and not go bankrupt](https://itsilesia.com/kubernetes-for-poor-how-to-run-your-cluster-and-not-go-bankrupt/) By Aleksander Grzybowski - Nov 13, 2018
- [Diary of a GKE Journeyman - Running your personal Kubernetes Cluster for (almost) free on GKE](https://mehdi.me/running-a-personal-kubernetes-cluster-for-almost-from-on-gke/) By Mehdi El Gueddari - Mar 22, 2019 
- [Collection of tools and code examples to demonstrate best practices in using Amazon EC2 Spot Instances.](https://github.com/awslabs/ec2-spot-labs)
- [AWS Spot Instance Advisor](https://aws.amazon.com/ec2/spot/instance-advisor)

### Kubernetes' distributions

- [MicroK8s - Zero-ops Kubernetes for workstations and edge / IoT](https://microk8s.io/) By Ubuntu
- [K3s - Lightweight Kubernetes for IoT &amp; Edge computing](https://k3s.io/) By Rancher
- [KinD - Kubernetes in Docker](https://github.com/kubernetes-sigs/kind) By Kubernetes SIGs
- [Typhoon - Minimal and free Kubernetes distribution](https://github.com/poseidon/typhoon) By poseidon</content><author><name></name></author><category term="aws" /><category term="docker" /><category term="kubernetes" /><category term="data plane" /><category term="microservice" /><summary type="html">I want to build a Container-based Cloud to deploy any kind of workload (RESTful API, Microservices, Event-Driven, Functions, etc.) but it should be affordable, ready to use, reliable, secure and productionable. This means: Productionable: should be fully functional and ready to be used as a production environment. Reliable and Secure: able to improve the security level by implementing more security controls, at least fully isolated secure private networking. Affordable: cheaper. Ready to use: able to be automated (DevOps and IaC) with a mature management API. Below a high level architecture of Container-based Cloud I want to get. I will focus on the Service Mesh Data Plane. These requeriments restric some options, all of them using any Public Cloud Provider, but considering the AWS Spot Instances and Google Cloud Preemptible VM Instances. Unfortunately Microsoft Azure only provides Low-Priority VMs to be used from Azure Batch Service. But if you are new user, you could apply for using the Free Tier in all of 3 Cloud Providers.</summary></entry><entry><title type="html">Migrating WordPress.com’s blog to GitHub Pages with Jekyll - Part 2</title><link href="http://localhost:4000/2019/12/10/migrating-wordpress-com-blog-to-github-pages-with-jekyll-part2" rel="alternate" type="text/html" title="Migrating WordPress.com's blog to GitHub Pages with Jekyll - Part 2" /><published>2019-12-10T10:00:00+01:00</published><updated>2019-12-10T10:00:00+01:00</updated><id>http://localhost:4000/2019/12/10/migrating-wordpress-com-blog-to-github-pages-with-jekyll-part2</id><content type="html" xml:base="http://localhost:4000/2019/12/10/migrating-wordpress-com-blog-to-github-pages-with-jekyll-part2">In the first blog post [I explained how to export your WordPress.com blog and use it to generate your static blog site to be hosted in GitHub Pages](/2019/10/14/migrating-wordpress-com-blog-to-github-pages-with-jekyll-part1 &quot;Migrating WordPress.com's blog to GitHub Pages with Jekyll - Part 1&quot;). Now, in this blog post (Part 2) I will explain how to manage the look&amp;feel, theme, layouts and pagination of a previous migrated WordPress.com's blog to GitHub Pages. 
Also I'll explain how to convert all HTML post files, obtained by using the `JekyllImport::Importers::WordpressDotCom`, to Markdown format by using a simple Python script.

![Migrating WordPress.com's blog to GitHub Pages by using Jekyll Part2](/assets/img/20191210-wp-github-jekyll-python-part2-1.png){:width=&quot;500&quot;}

&lt;!-- more --&gt;

## Look&amp;Feel: Themes and Layouts

When I created the Jekyll site (by running the `jekyll new &lt;PATH&gt;` command), Jekyll installed a site that uses a gem-based theme called [Minima](https://github.com/jekyll/minima).

Then, the best way to change the Look&amp;Feel of your Github Page site is changing existing Theme/Layout; Jekyll supports an easy way to do it and here this is explained very well: 

* [Jekyll Layouts](https://jekyllrb.com/docs/layouts/)
* [Jekyll Themes](https://jekyllrb.com/docs/themes/)

So, in order to make changes in the Look&amp;Feel I will override the Minima's Gem. First of all I'll locate where the Minima's Theme/Layout Gem is:

```sh
chilcano@inti:~/git-repos/ghpages-holosec$ bundle show
Gems included by the bundle:
  * addressable (2.7.0)
  * bundler (2.0.2)
  * colorator (1.1.0)
  * concurrent-ruby (1.1.5)
  * em-websocket (0.5.1)
  * eventmachine (1.2.7)
  * fastercsv (1.5.5)
  * ffi (1.11.1)
  * forwardable-extended (2.6.0)
  * hpricot (0.8.6)
  * http_parser.rb (0.6.0)
  * i18n (1.7.0)
  * jekyll (4.0.0)
  * jekyll-feed (0.12.1)
  * jekyll-import (0.19.0)
  * jekyll-paginate (1.1.0)
  * jekyll-sass-converter (2.0.1)
  * jekyll-seo-tag (2.6.1)
  * jekyll-watch (2.2.1)
  * kramdown (2.1.0)
  * kramdown-parser-gfm (1.1.0)
  * liquid (4.0.3)
  * listen (3.2.0)
  * mercenary (0.3.6)
  * mini_portile2 (2.4.0)
  * minima (2.5.1)
...

chilcano@inti:~/git-repos/ghpages-holosec$ bundle show minima
/home/chilcano/git-repos/ghpages-holosec/vendor/bundle/ruby/2.5.0/gems/minima-2.5.1

chilcano@inti:~/git-repos/ghpages-holosec$ tree /home/chilcano/git-repos/ghpages-holosec/vendor/bundle/ruby/2.5.0/gems/minima-2.5.1
/home/chilcano/git-repos/ghpages-holosec/vendor/bundle/ruby/2.5.0/gems/minima-2.5.1
├── assets
│   ├── main.scss
│   └── minima-social-icons.svg
├── _includes
│   ├── disqus_comments.html
│   ├── footer.html
│   ├── google-analytics.html
│   ├── header.html
│   ├── head.html
│   ├── icon-github.html
│   ├── icon-github.svg
│   ├── icon-twitter.html
│   ├── icon-twitter.svg
│   └── social.html
├── _layouts
│   ├── default.html
│   ├── home.html
│   ├── page.html
│   └── post.html
├── LICENSE.txt
├── README.md
└── _sass
    ├── minima
    │   ├── _base.scss
    │   ├── _layout.scss
    │   └── _syntax-highlighting.scss
    └── minima.scss

5 directories, 22 files
```


With a clear understanding of the theme’s files, you can now override any theme file by creating a similarly named file in your Jekyll site directory.
For example:

1. Create the `&lt;GHPAGE_SITE_ROOT&gt;/_layouts/` and/or `&lt;GHPAGE_SITE_ROOT&gt;/assets/` folder if they don't exist.
2. Create a specific and simlarly file under `&lt;GHPAGE_SITE_ROOT&gt;/_layouts/`, if you want to change that specific part of Layout, or under `&lt;GHPAGE_SITE_ROOT&gt;/assets/`, if you want to change the Theme.
3. Once done you can add your own code in these created files. In my case I've created `home.html` and `post.html` in `&lt;GHPAGE_SITE_ROOT&gt;/_layouts_/` to modify the Minima's Layout and created `main.scss` in `&lt;GHPAGE_SITE_ROOT&gt;/assets/` to change the colors and fonts.

You can view these files here:

* `&lt;GHPAGE_SITE_ROOT&gt;/assets/main.scss`
* `&lt;GHPAGE_SITE_ROOT&gt;/_layouts/home.html`
* `&lt;GHPAGE_SITE_ROOT&gt;/_layouts/post.html`


## Blog post Pagination and Excerpts

By default Jekyll since version 3 includes the `jekyll-paginate` plugin in the `Gemfile` and in the `_config.yml` under the plugins section.
But if you don't have it, add it with this command:

```sh
chilcano@inti:~/git-repos/ghpages-holosec$ bundle add jekyll-paginate
```

To configure the Blog pagination and the showing excerpts we have to edit the `_config.yml` file which affect at global level.

```yaml
...
...
## Pagination for blog posts: https://jekyllrb.com/docs/pagination/
paginate: 5
paginate_path: &quot;/blog/pg:num&quot;

#show_excerpts: false
excerpt_separator: &lt;!-- more --&gt;
```

Once done, we have to create the `&lt;GHPAGE_SITE_ROOT&gt;/blog/index.html` which it will render the Blog Posts list. I recommend to start with the code snippet available [here - https://jekyllrb.com/docs/pagination/](https://jekyllrb.com/docs/pagination/), or if you prefer you can use my modified `&lt;GHPAGE_SITE_ROOT&gt;/blog/index.html` [file](/blog/index.html).

```yaml
---
layout: page
title: Blog
show_excerpts: true
#excerpt_separator: &lt;!-- more --&gt;
---
...
...
```

Where:

- `paginate: 5`: means 5 blog post for each page.
- `paginate_path: &quot;/blog/pg:num&quot;`: the path to the file with which all Blog Posts will be rendered and viewed, also it will include the pagination controls.
- `#show_excerpts: false`: inclusion of excerpts is disabled at global level, but enabled in `&lt;GHPAGE_SITE_ROOT&gt;/blog/index.html`.
- `excerpt_separator: &lt;!-- more --&gt;`: excerpt deparator is enabled at global level, but disabled in `&lt;GHPAGE_SITE_ROOT&gt;/blog/index.html`.


## Converting HTML post files to Markdown using Python

If you have gone through exportation and importation process you will have a Blog with some WordPress's HTML with unrecognizable tags and metadata, and missing links, that is normal and annoying too. For that, I looked out for some Ruby Gems or Python scripts to convert to Markdown, tweak the code and improve the readibility of new Markdown converted Posts.

I've used the (`Jekyll WordPress.com Importer`)[https://import.jekyllrb.com/docs/wordpressdotcom/], it extracts all posts and download attachments from the WordPress Export XML File and place them into `&lt;GHPAGE_SITE_ROOT&gt;/_posts/` and `&lt;GHPAGE_SITE_ROOT&gt;/assets/` folders, once done I'll run the prepared Python script:


Activate the Python 3 Environment. If you want to know how to get it, here I've prepared its explanation: [Setting a Python 3 local programming environment](/2019/12/08/python3-setting-a-local-env &quot;Setting a Python 3 local programming environment&quot;).

```sh
chilcano@inti:~/git-repos/ghpages-holosec$ source ../abc/myenv3/bin/activate
(myenv3) chilcano@inti:~/git-repos/ghpages-holosec$ 
```

Once activated, execute the provided Python script.

```sh
(myenv3) chilcano@inti:~/git-repos/ghpages-holosec$ python ./wp_export/simple_html_wp_to_md.py ./_posts/
&gt; Loading and splitting 89 HTML files from ./_posts/
	 2010-09-10-agile-bpm-systems-development-with-camunda-fox-and-alfresco-activiti.html
...
&gt; Saving 89 markdown files in ./_posts/
	 2010-09-10-agile-bpm-systems-development-with-camunda-fox-and-alfresco-activiti.md
...
```

And I will get:

1. Convert HTML to Markdown.
2. Update all Markdown files to Jekyll's Markdown with a Front Matter's header.
3. Tweak all Markdown files to do compatible with Jekyll, it is removing no used tags, metadata, removing blank lines, adding break lines, etc.

You can download the Python script here: [simple_html_wp_to_md.py](/wp_export/simple_html_wp_to_md.py).

I had issues trying to improve the generated Markdown files, I used `BeautifulSoup` to manage XML, `html2text` to generate the Markdown and `re` massively to tweak the Markdown. If you know a best option, please, let me know it.

## More things to consider

- [A Jekyll plugin that copies static files from the _posts to the _site folder](https://nhoizey.github.io/jekyll-postfiles/)
- [Building a Stats Page for Jekyll Blogs](https://www.raymondcamden.com/2018/07/21/building-a-stats-page-for-jekyll-blogs)
- [A simple script to generate some stats about a Jekyll blog.](https://github.com/fluca1978/jekyll-simple-stats)
- [Plugin to easily add webanalytics to your jekyll site](https://github.com/hendrikschneider/jekyll-analytics)
- [Google Analytics for Jekyll](https://desiredpersona.com/google-analytics-jekyll/)


That's all, if you find this post helpful, please, share it.
Regards.

## References

- [Migrating WordPress.com's blog to GitHub Pages with Jekyll - Part 1](/2019/10/14/migrating-wordpress-com-blog-to-github-pages-with-jekyll-part1)
- [Jekyll Layouts](https://jekyllrb.com/docs/layouts/)
- [Jekyll Themes](https://jekyllrb.com/docs/themes/)
- [Jekyll Pagination](https://jekyllrb.com/docs/pagination/)
- [WordPress.com Jekyll Importer](https://import.jekyllrb.com/docs/wordpressdotcom/)</content><author><name></name></author><category term="github" /><category term="wordpress" /><category term="jekyll" /><category term="migration" /><category term="python" /><summary type="html">In the first blog post I explained how to export your WordPress.com blog and use it to generate your static blog site to be hosted in GitHub Pages. Now, in this blog post (Part 2) I will explain how to manage the look&amp;amp;feel, theme, layouts and pagination of a previous migrated WordPress.com’s blog to GitHub Pages. Also I’ll explain how to convert all HTML post files, obtained by using the JekyllImport::Importers::WordpressDotCom, to Markdown format by using a simple Python script.</summary></entry><entry><title type="html">Setting a Python 3 local programming environment</title><link href="http://localhost:4000/2019/12/08/python3-setting-a-local-env" rel="alternate" type="text/html" title="Setting a Python 3 local programming environment" /><published>2019-12-08T10:00:00+01:00</published><updated>2019-12-08T10:00:00+01:00</updated><id>http://localhost:4000/2019/12/08/python3-setup-a-local-env</id><content type="html" xml:base="http://localhost:4000/2019/12/08/python3-setting-a-local-env">This post will guide you through installing Python 3, and Python 2.x, on your local Linux machine and setting up a programming environment via the command line. This post will explicitly cover the installation procedures for Ubuntu 18.04 or above, but the general principles apply to any other distribution of Debian Linux.

![Python 3](/assets/img/20191208-python.png &quot;Setting a Python 3 local programming environment&quot;)


&lt;!-- more --&gt;


## Step 1 — Setting Up Python 3

```sh
$ python3 -V

$ sudo apt install -y python-pip
$ sudo apt install -y python3-pip

// way to install python modules
$ pip install package_name
$ pip3 install package_name

$ sudo apt install build-essential libssl-dev libffi-dev python-dev
```


## Step 2 — Setting Up a Virtual Environment

```sh
// using Apt
$ sudo apt install -y virtualenv
$ sudo apt install -y python3-venv

// using Pip
$ pip install virtualenv
$ pip3 install virtualenv
```

With this installed, we are ready to create environments. Let’s either choose which directory we would like to put our Python programming environments in, or create a new directory with mkdir, as in:

```sh
$ mkdir abc
$ cd abc
```

Once you are in the directory where you would like the environments to live, you can create an environment by running the following command:

```sh
$ virtualenv -p /usr/bin/python myenv27
$ python3 -m venv myenv3
```

Essentially, this sets up a new directory that contains a few items which we can view with the ls command:

```sh
$ ls myenv27/
bin  include  lib  local  share

$ ls myenv3/
bin  include  lib  lib64  pyvenv.cfg  share
```

## Step 3 — Activate the Python Environment

To use this environment, you need to activate it, which you can do by typing the following command that calls the activate script:

```sh
$ source myenv27/bin/activate
(myenv27) chilcano@inti:~/git-repos/abc$ 

$ source myenv3/bin/activate
(myenv3) chilcano@inti:~/git-repos/abc$ 
```

&gt; Note: Within the virtual environment, you can use the command python instead of python3, and pip instead of pip3 if you would prefer. If you use Python 3 on your machine outside of an environment, you will need to use the python3 and pip3 commands exclusively.

## Step 4 — Creating a Python3 Program


```sh
(myenv27) chilcano@inti:~/git-repos/abc$ pip install pylint python-dateutil BeautifulSoup4 html2text slugify wget

(myenv3) chilcano@inti:~/git-repos/abc$ python3 -m pip install -U pylint
(myenv3) chilcano@inti:~/git-repos/abc$ pip install pylint python-dateutil BeautifulSoup4 html2text slugify
(myenv3) chilcano@inti:~/git-repos/abc$ pip install pyyaml
```

&gt; To leave the environment, simply type the command `deactivate` and you will return to your original directory.


## References

- [https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04](https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04)
- [https://www.digitalocean.com/community/tutorials/how-to-import-modules-in-python-3](https://www.digitalocean.com/community/tutorials/how-to-import-modules-in-python-3)
- [https://help.dreamhost.com/hc/en-us/articles/215489338-Installing-and-using-virtualenv-with-Python-2](https://help.dreamhost.com/hc/en-us/articles/215489338-Installing-and-using-virtualenv-with-Python-2)</content><author><name></name></author><category term="python" /><summary type="html">This post will guide you through installing Python 3, and Python 2.x, on your local Linux machine and setting up a programming environment via the command line. This post will explicitly cover the installation procedures for Ubuntu 18.04 or above, but the general principles apply to any other distribution of Debian Linux.</summary></entry></feed>