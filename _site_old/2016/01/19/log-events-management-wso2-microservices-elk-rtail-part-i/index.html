<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Log Events Management in WSO2 (Micro)services: ELK &amp; rTail (Part I) | Holistic Security</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Log Events Management in WSO2 (Micro)services: ELK &amp; rTail (Part I)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The log event management is a task very important when working with (Micro)services. If you collect-store-index all logs, then you will be able to create your business metrics (KPI). You only must understand what by collecting logs you have to use special tools with technical special requirements: Huge amout of logs could transform in your BigData asset. You have to collect and query your logs in real time if you think your Application is critical. You have to manage in agile way the life cycle of your data (your logs), they are an asset very important for your Organization. Kibana - Viewing WSO2 and Wiremock raw log events" />
<meta property="og:description" content="The log event management is a task very important when working with (Micro)services. If you collect-store-index all logs, then you will be able to create your business metrics (KPI). You only must understand what by collecting logs you have to use special tools with technical special requirements: Huge amout of logs could transform in your BigData asset. You have to collect and query your logs in real time if you think your Application is critical. You have to manage in agile way the life cycle of your data (your logs), they are an asset very important for your Organization. Kibana - Viewing WSO2 and Wiremock raw log events" />
<link rel="canonical" href="https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/" />
<meta property="og:url" content="https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/" />
<meta property="og:site_name" content="Holistic Security" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-01-19T17:49:31+01:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/"},"url":"https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/","headline":"Log Events Management in WSO2 (Micro)services: ELK &amp; rTail (Part I)","dateModified":"2016-01-19T17:49:31+01:00","datePublished":"2016-01-19T17:49:31+01:00","description":"The log event management is a task very important when working with (Micro)services. If you collect-store-index all logs, then you will be able to create your business metrics (KPI). You only must understand what by collecting logs you have to use special tools with technical special requirements: Huge amout of logs could transform in your BigData asset. You have to collect and query your logs in real time if you think your Application is critical. You have to manage in agile way the life cycle of your data (your logs), they are an asset very important for your Organization. Kibana - Viewing WSO2 and Wiremock raw log events","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://holisticsecurity.io/feed.xml" title="Holistic Security" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-156433649-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/"><img src="/assets/img/logo-holosec.png" width="100" /> Holistic Security</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/">Home</a><a class="page-link" href="/blog/">Blog</a><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Log Events Management in WSO2 (Micro)services: ELK &amp; rTail (Part I)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2016-01-19T17:49:31+01:00" itemprop="datePublished">Jan 19, 2016 
      </time>&sim; MICROSERVICES · SOA
      &sim; DOCKER · ELK · LOGGING · RTAIL · VAGRANT · WIREMOCK · WSO2
    </p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>The log event management is a task very important when working with (Micro)services. If you collect-store-index all logs, then you will be able to create your business metrics (KPI). You only must understand what by collecting logs you have to use special tools with technical special requirements:</p>
<ul>
  <li>Huge amout of logs could transform in your <code class="highlighter-rouge">BigData</code> asset.</li>
  <li>You have to collect and query your logs in real time if you think your Application is critical.</li>
  <li>You have to <code class="highlighter-rouge">manage</code> in agile way the life cycle of your data (your logs), they are an asset very important for your Organization.</li>
</ul>

<p><img src="/assets/blog20160114_logs_elk_microservices_wso2/blog-chilcano-logs-wso2-docker-elk-rtail-0-architecture.png" alt="" /><br />
<em>Kibana - Viewing WSO2 and Wiremock raw log events</em></p>

<!-- more -->

<p>You should be agile, for this reason, <a href="https://www.elastic.co">Elasticsearch-Logstash-Kibana</a> is the perfect Stack to do that in an agile way.<br />
Really, there are many tools out there, opensource, commercial, on-cloud, such as log.io, Clarity, rTail, Tailon, frontail, etc. In my opinion, for a development environment, the most simple, fresh and lightweight tool is rTail (http://rtail.org), with rTail I can collect different log files, track and visualize them from a Browser in real time. rTail is very easy to use, just install NodeJS and deploy rTail application and you will be ready to send any type of traces to Browser directly avoiding store/persist logs, index and parse/filter them.<br />
Well, this first blog post I will explain how to use ELK to collect, store and view the different log event of WSO2 ESB, API Manager, DSS, GREG and Wiremock.</p>

<h2 id="elk-elasticsearch-logstash-kibana">ELK (Elasticsearch, Logstash, Kibana)</h2>

<h3 id="1-starting-with-elk-docker-container">1. Starting with ELK Docker Container</h3>

<p><strong>1) Prepare the ELK container</strong></p>

<p>We gonna use an existing Docker Image with ELK created by <a href="https://github.com/spujadas">Sébastien Pujadas</a> <code class="highlighter-rouge">(http://elk-docker.readthedocs.org)</code> previously configured ready to be used. This Docker Image contains:</p>
<ul>
  <li>Elasticsearch (version 2.1.1)</li>
  <li>Logstash (version 2.1.1)</li>
  <li>Kibana (version 4.3.1)</li>
</ul>

<p>Then, let’s do it. Start the Docker daemon and login Docker Hub:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker login  
Username <span class="o">(</span>chilcano<span class="o">)</span>:  
WARNING: login credentials saved <span class="k">in</span> /Users/Chilcano/.docker/config.json  
Login Succeeded
<span class="nv">$ </span>docker pull sebp/elk  
Using default tag: latest  
latest: Pulling from sebp/elk  
de9c48daf08c: Pull <span class="nb">complete</span>  
...  
96f071b7a8e2: Pull <span class="nb">complete  
</span>Digest: sha256:ce7b3a1dfe285d1d9b862905bf0ee6df951f1a035120b92af71280217b6f3422  
Status: Downloaded newer image <span class="k">for </span>sebp/elk:latest  
</code></pre></div></div>

<p><strong>2) Run the container</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-p</span> 5601:5601 <span class="nt">-p</span> 9200:9200 <span class="nt">-p</span> 5044:5044 <span class="nt">-p</span> 5000:5000 <span class="nt">-it</span> <span class="nt">--name</span> elk sebp/elk  
<span class="k">*</span> Starting Elasticsearch Server  
sysctl: setting key <span class="s2">"vm.max_map_count"</span>: Read-only file system logstash started. <span class="o">[</span> OK <span class="o">]</span>
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>1/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>2/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>3/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>4/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>5/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>6/30<span class="o">)</span>  
waiting <span class="k">for </span>Elasticsearch to be up <span class="o">(</span>7/30<span class="o">)</span>  
<span class="k">*</span> Starting Kibana4 <span class="o">[</span> OK <span class="o">]</span>  

<span class="o">[</span>2016-01-14 08:48:01,215][INFO <span class="o">][</span>node <span class="o">]</span> <span class="o">[</span>Zero] initialized  
<span class="o">[</span>2016-01-14 08:48:01,216][INFO <span class="o">][</span>node <span class="o">]</span> <span class="o">[</span>Zero] starting ...  
<span class="o">[</span>2016-01-14 08:48:01,259][WARN <span class="o">][</span>common.network <span class="o">]</span> <span class="o">[</span>Zero] publish address: <span class="o">{</span>0.0.0.0<span class="o">}</span> is a wildcard address, falling back to first non-loopback: <span class="o">{</span>172.17.0.2<span class="o">}</span>  
<span class="o">[</span>2016-01-14 08:48:01,259][INFO <span class="o">][</span>transport <span class="o">]</span> <span class="o">[</span>Zero] publish_address <span class="o">{</span>172.17.0.2:9300<span class="o">}</span>, bound_addresses <span class="o">{[</span>::]:9300<span class="o">}</span>  
<span class="o">[</span>2016-01-14 08:48:01,297][INFO <span class="o">][</span>discovery <span class="o">]</span> <span class="o">[</span>Zero] elasticsearch/vyxjAXavQbOnh7uA7HO_7g  
<span class="o">[</span>2016-01-14 08:48:04,341][INFO <span class="o">][</span>cluster.service <span class="o">]</span> <span class="o">[</span>Zero] new_master <span class="o">{</span>Zero<span class="o">}{</span>vyxjAXavQbOnh7uA7HO_7g<span class="o">}{</span>172.17.0.2<span class="o">}{</span>172.17.0.2:9300<span class="o">}</span>, reason: zen-disco-join<span class="o">(</span>elected_as_master, <span class="o">[</span>0] joins received<span class="o">)</span>  
<span class="o">[</span>2016-01-14 08:48:04,365][WARN <span class="o">][</span>common.network <span class="o">]</span> <span class="o">[</span>Zero] publish address: <span class="o">{</span>0.0.0.0<span class="o">}</span> is a wildcard address, falling back to first non-loopback: <span class="o">{</span>172.17.0.2<span class="o">}</span>  
<span class="o">[</span>2016-01-14 08:48:04,365][INFO <span class="o">][</span>http <span class="o">]</span> <span class="o">[</span>Zero] publish_address <span class="o">{</span>172.17.0.2:9200<span class="o">}</span>, bound_addresses <span class="o">{[</span>::]:9200<span class="o">}</span>  
<span class="o">[</span>2016-01-14 08:48:04,365][INFO <span class="o">][</span>node <span class="o">]</span> <span class="o">[</span>Zero] started  
<span class="o">[</span>2016-01-14 08:48:04,384][INFO <span class="o">][</span>gateway <span class="o">]</span> <span class="o">[</span>Zero] recovered <span class="o">[</span>0] indices into cluster_state  
<span class="o">[</span>2016-01-14 08:48:13,180][INFO <span class="o">][</span>cluster.metadata <span class="o">]</span> <span class="o">[</span>Zero] <span class="o">[</span>.kibana] creating index, cause <span class="o">[</span>api], templates <span class="o">[]</span>, shards <span class="o">[</span>1]/[1], mappings <span class="o">[</span>config]  
</code></pre></div></div>

<p><strong>3) Check the status of ELK in the running container</strong></p>

<p>In other Terminal/Shell execute the next:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker-machine <span class="nb">ls  
</span>NAME ACTIVE DRIVER STATE URL SWARM ERRORS  
default - virtualbox Running tcp://192.168.99.100:2376  
machine-dev - virtualbox Stopped  
machine-test - virtualbox Stopped
<span class="nv">$ </span>docker-machine <span class="nb">env </span>default  
<span class="nb">export </span><span class="nv">DOCKER_TLS_VERIFY</span><span class="o">=</span><span class="s2">"1"</span>  
<span class="nb">export </span><span class="nv">DOCKER_HOST</span><span class="o">=</span><span class="s2">"tcp://192.168.99.100:2376"</span>  
<span class="nb">export </span><span class="nv">DOCKER_CERT_PATH</span><span class="o">=</span><span class="s2">"/Users/Chilcano/.docker/machine/machines/default"</span>  
<span class="nb">export </span><span class="nv">DOCKER_MACHINE_NAME</span><span class="o">=</span><span class="s2">"default"</span>  

<span class="c"># Run this command to configure your shell:  </span>

<span class="c"># eval "$(docker-machine env default)"</span>
<span class="nv">$ </span><span class="nb">eval</span> <span class="s2">"</span><span class="si">$(</span>docker-machine <span class="nb">env </span>default<span class="si">)</span><span class="s2">"</span>
<span class="nv">$ </span>docker ps  
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES  
788b97b04e9b sebp/elk <span class="s2">"/usr/local/bin/start"</span> 9 minutes ago Up 9 minutes 0.0.0.0:5000-&gt;5000/tcp, 0.0.0.0:5044-&gt;5044/tcp, 0.0.0.0:5601-&gt;5601/tcp, 0.0.0.0:9200-&gt;9200/tcp, 9300/tcp elk  
</code></pre></div></div>

<p>The ports opened are:</p>
<ul>
  <li>5601 (Kibana web interface).</li>
  <li>9200 (Elasticsearch JSON interface).</li>
  <li>5044 (Logstash Beats interface, receives logs from Beats such as Filebeat).</li>
  <li>5000 (Logstash Lumberjack interface, receives logs from Logstash forwarders).</li>
</ul>

<p><strong>4) Check Elasticsearch server</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"User-Agent: Mozilla"</span> <span class="nt">-H</span> <span class="s2">"Origin: http://example.com"</span> <span class="nt">-i</span> 192.168.99.100:9200  
HTTP/1.1 200 OK  
Content-Type: application/json<span class="p">;</span> <span class="nv">charset</span><span class="o">=</span>UTF-8  
Content-Length: 313
<span class="o">{</span>  
<span class="s2">"name"</span> : <span class="s2">"Zero"</span>,  
<span class="s2">"cluster_name"</span> : <span class="s2">"elasticsearch"</span>,  
<span class="s2">"version"</span> : <span class="o">{</span>  
<span class="s2">"number"</span> : <span class="s2">"2.1.1"</span>,  
<span class="s2">"build_hash"</span> : <span class="s2">"40e2c53a6b6c2972b3d13846e450e66f4375bd71"</span>,  
<span class="s2">"build_timestamp"</span> : <span class="s2">"2015-12-15T13:05:55Z"</span>,  
<span class="s2">"build_snapshot"</span> : <span class="nb">false</span>,  
<span class="s2">"lucene_version"</span> : <span class="s2">"5.3.1"</span>  
<span class="o">}</span>,  
<span class="s2">"tagline"</span> : <span class="s2">"You Know, for Search"</span>  
<span class="o">}</span>  
</code></pre></div></div>

<p>And if you want to stop and start again the container, just execute the next:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop elk  
elk
<span class="nv">$ </span>docker start elk  
elk  
</code></pre></div></div>

<p><strong>5) Sending a dummy logs to ELK</strong></p>

<p>In another terminal execute the next:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> elk /bin/bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> elk /bin/bash  
root@788b97b04e9b:/# /opt/logstash/bin/logstash <span class="nt">-e</span> <span class="s1">'input { stdin { } } output { elasticsearch { hosts =&gt; ["localhost"] } }'</span>  
Settings: Default filter workers: 1  
Logstash startup completed  
Hola Chilcano!!  
^CSIGINT received. Shutting down the pipeline. <span class="o">{</span>:level<span class="o">=&gt;</span>:warn<span class="o">}</span>
Logstash shutdown completed  
root@788b97b04e9b:/#  
</code></pre></div></div>

<p>In other terminal using cURL or from a browser:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl http://192.168.99.100:9200/_search?pretty  
<span class="o">{</span>  
<span class="s2">"took"</span> : 5,  
<span class="s2">"timed_out"</span> : <span class="nb">false</span>,  
<span class="s2">"_shards"</span> : <span class="o">{</span>  
<span class="s2">"total"</span> : 6,  
<span class="s2">"successful"</span> : 6,  
<span class="s2">"failed"</span> : 0  
<span class="o">}</span>,  
<span class="s2">"hits"</span> : <span class="o">{</span>  
<span class="s2">"total"</span> : 2,  
<span class="s2">"max_score"</span> : 1.0,  
<span class="s2">"hits"</span> : <span class="o">[</span> <span class="o">{</span>  
<span class="s2">"_index"</span> : <span class="s2">".kibana"</span>,  
<span class="s2">"_type"</span> : <span class="s2">"config"</span>,  
<span class="s2">"_id"</span> : <span class="s2">"4.3.1"</span>,  
<span class="s2">"_score"</span> : 1.0,  
<span class="s2">"_source"</span>:<span class="o">{</span><span class="s2">"buildNum"</span>:9517<span class="o">}</span>  
<span class="o">}</span>, <span class="o">{</span>  
<span class="s2">"_index"</span> : <span class="s2">"logstash-2016.01.14"</span>,  
<span class="s2">"_type"</span> : <span class="s2">"logs"</span>,  
<span class="s2">"_id"</span> : <span class="s2">"AVJA8Na_dQWajjStHmJN"</span>,  
<span class="s2">"_score"</span> : 1.0,  
<span class="s2">"_source"</span>:<span class="o">{</span><span class="s2">"message"</span>:<span class="s2">"Hola Chilcano!!"</span>,<span class="s2">"@version"</span>:<span class="s2">"1"</span>,<span class="s2">"@timestamp"</span>:<span class="s2">"2016-01-14T16:21:11.231Z"</span>,<span class="s2">"host"</span>:<span class="s2">"788b97b04e9b"</span><span class="o">}</span>  
<span class="o">}</span> <span class="o">]</span>  
<span class="o">}</span>  
<span class="o">}</span>  
</code></pre></div></div>

<p>… and from the Kibana web console (<code class="highlighter-rouge">http://192.168.99.100:5601</code>) to view the incoming dummy log event. Before configure Kibana by creating a <code class="highlighter-rouge">Index Pattern</code> with <code class="highlighter-rouge">logstash-*</code> and <code class="highlighter-rouge">Time-field name: @timestamp</code>, as shown below:</p>

<p><img src="/assets/blog20160114_logs_elk_microservices_wso2/blog-chilcano-logs-wso2-docker-elk-rtail-1-kibana.png" alt="" /><br />
<em>Kibana - Creating a Index Pattern</em></p>

<p><img src="/assets/blog20160114_logs_elk_microservices_wso2/blog-chilcano-logs-wso2-docker-elk-rtail-2-kibana-dummy-logs.png" alt="" /><br />
<em>Kibana - Selecting the field of the new Index Pattern</em></p>

<p><img src="/assets/blog20160114_logs_elk_microservices_wso2/blog-chilcano-logs-wso2-docker-elk-rtail-3-kibana-dummy-logs-discovery.png" alt="Kibana - Viewing a dummy log event" />
<em>Kibana - Viewing a dummy log event</em></p>

<h3 id="2-sending-wso2-logs-to-the-elk-docker-container">2. Sending WSO2 logs to the ELK Docker container</h3>

<p>For this part I will use a Vagrant box with several WSO2 products pre-installed and pre-configured. I explained how to use It in this blog, for further details check <a href="https://holisticsecurity.io/2015/11/11/creating-a-vm-with-wso2-servers-for-development/">that post</a>.</p>

<blockquote>
  <p>Filebeat is a lightweight, open source shipper for log file data. As the next-generation<br />
 Logstash Forwarder, Filebeat tails logs and quickly sends this information to Logstash<br />
 for further parsing and enrichment or to Elasticsearch for centralized storage and analysis.<br />
 <em><a href="https://www.elastic.co/products/beats/filebeat">www.elastic.co/products/beats/filebeat</a></em></p>
</blockquote>

<p><strong>1) Start the WSO2 Vagrant box</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/chilcano/box-vagrant-wso2-dev-srv.git
<span class="nv">$ </span><span class="nb">cd </span>box-vagrant-wso2-dev-srv
<span class="nv">$ </span>vagrant up  
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh  
Welcome to Ubuntu 14.04.3 LTS <span class="o">(</span>GNU/Linux 3.13.0-67-generic i686<span class="o">)</span>
<span class="k">*</span> Documentation: https://help.ubuntu.com/
System information as of Tue Jan 12 10:41:00 UTC 2016
System load: 1.76 Processes: 108  
Usage of /: 33.9% of 39.34GB Users logged <span class="k">in</span>: 0  
Memory usage: 42% IP address <span class="k">for </span>eth0: 10.0.2.15  
Swap usage: 0% IP address <span class="k">for </span>eth1: 192.168.11.20
Graph this data and manage this system at:  
https://landscape.canonical.com/
Get cloud support with Ubuntu Advantage Cloud Guest:  
http://www.ubuntu.com/business/services/cloud
9 packages can be updated.  
7 updates are security updates.
Last login: Tue Jan 12 10:41:01 2016 from 10.0.2.2

<span class="o">[</span>11:04 AM]-[vagrant@wso2-dev-srv-01]-[~]  
<span class="nv">$ </span><span class="nb">cd</span> /opt/

<span class="o">[</span>11:04 AM]-[vagrant@wso2-dev-srv-01]-[/opt]  
<span class="nv">$ </span>ll  
total 40  
drwxr-xr-x 11 vagrant vagrant 4096 Nov 30 23:43 activemq/  
drwxr-xr-x 2 vagrant vagrant 4096 Jan 12 10:39 rtail/  
drwxr-xr-x 9 root root 4096 Nov 18 18:18 VBoxGuestAdditions-4.3.10/  
drwxr-xr-x 4 vagrant vagrant 4096 Nov 30 15:41 wiremock/  
drwxr-xr-x 15 vagrant vagrant 4096 Nov 30 15:41 wso2am02a/  
drwxr-xr-x 10 vagrant vagrant 4096 Jan 12 10:40 wso2dss01a/  
drwxr-xr-x 11 vagrant vagrant 4096 Nov 23 12:44 wso2esb01a/  
drwxr-xr-x 11 vagrant vagrant 4096 Nov 23 12:45 wso2esb02a/  
drwxr-xr-x 10 vagrant vagrant 4096 Nov 30 23:14 wso2esb490/  
drwxr-xr-x 13 vagrant vagrant 4096 Jan 12 10:41 wso2greg01a/  

</code></pre></div></div>
<p>If you already are running this Vagrant box with WSO2 ESB, WSO2 API Manager, WSO2 DSS, Wiremock, etc. then the next step is configure It to send the different generated logs to ELK Docker Container.<br />
In the documentation explains that It will be used <a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a>, for that we have to install and configure Filebeat in this Vagrant box.</p>

<p><strong>2) Install Filebeat into Vagrant box</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>curl <span class="nt">-L</span> <span class="nt">-O</span> https://download.elastic.co/beats/filebeat/filebeat_1.0.1_i386.deb  
<span class="nv">$ </span><span class="nb">sudo </span>dpkg <span class="nt">-i</span> filebeat_1.0.1_i386.deb  
<span class="nv">$ </span><span class="nb">sudo rm </span>filebeat_1.0.1_i386.deb  
</code></pre></div></div>

<p><strong>3) Configure Filebeat to forward WSO2 logs to ELK Docker Container</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ll /etc/filebeat/  
total 20  
<span class="nt">-rw-r--r--</span> 1 root root 814 Dec 17 13:26 filebeat.template.json  
<span class="nt">-rw-r--r--</span> 1 root root 14541 Dec 17 13:26 filebeat.yml  
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>nano filebeat.yml
output:  
logstash:  
enabled: <span class="nb">true  
</span>hosts: <span class="o">[</span><span class="s2">"elk-docker:5044"</span><span class="o">]</span>  
<span class="nb">timeout</span>: 15  
tls:  
certificate_authorities: <span class="o">[</span><span class="s2">"/etc/pki/tls/certs/logstash-beats.crt"</span><span class="o">]</span>
filebeat:  
prospectors:  
-  
paths:  
<span class="se">\-</span> /opt/wso2esb01a/repository/logs/wso2carbon.log  
<span class="se">\-</span> /opt/wso2esb02a/repository/logs/wso2carbon.log  
<span class="se">\-</span> /opt/wso2am02a/repository/logs/wso2carbon.log  
<span class="se">\-</span> /opt/wso2dss01a/repository/logs/wso2carbon.log  
<span class="se">\-</span> /opt/wso2greg01a/repository/logs/wso2carbon.log  
document_type: log  
-  
paths:  
<span class="se">\-</span> /opt/wiremock/wiremock.log  
document_type: log  
logging:  
level: warning  
to_files: <span class="nb">true  
</span>to_syslog: <span class="nb">false
</span>files:  
path: /var/log/filebeat  
name: filebeat.log  
keepfiles: 7

</code></pre></div></div>
<p>Where <code class="highlighter-rouge">elk-docker:5044</code> is the hostname for the <code class="highlighter-rouge">192.168.99.100</code> added to <code class="highlighter-rouge">/etc/hosts</code> of Vagrant box.
Copy the <code class="highlighter-rouge">/etc/pki/tls/certs/logstash-beats.crt</code> file from Logstash Beats input plugin (ELK Docker Container) into <code class="highlighter-rouge">/etc/pki/tls/certs/logstash-beats.crt</code> (Vagrant box).</p>
<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo mkdir -p /etc/pki/tls/certs/  
$ cd /etc/pki/tls/certs/  
$ sudo wget https://raw.githubusercontent.com/spujadas/elk-docker/master/nginx-filebeat/logstash-beats.crt

### or from ELK container SCP the *.crt file to Vagrant (open 2222 port).  

$ scp -P 2222 /etc/pki/tls/certs/logstash-beats.crt vagrant@192.168.1.43:/etc/pki/tls/certs/logstash-beats.crt  
</code></pre></div></div>

<p>To avoid the below error, to update the <code class="highlighter-rouge">host</code> with a hostname (not IP address) as <code class="highlighter-rouge">elk-docker</code> in <code class="highlighter-rouge">/etc/filebeat/filebeat.yml</code> file, after that update also <code class="highlighter-rouge">/etc/hosts</code> with the appropiate IP Address.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo</span> /etc/init.d/filebeat start  
2016/01/15 17:30:22.910725 transport.go:125: ERR SSL client failed to connect with: x509: cannot validate certificate <span class="k">for </span>192.168.99.100 because it doesn<span class="s1">'t contain any IP SANs  
</span></code></pre></div></div>

<p><strong>4) Loading the Index Template in Elasticsearch</strong></p>

<p>Before starting Filebeat for the first time, run this command to load the default index template in Elasticsearch from the Vagrant box:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-XPUT</span> <span class="s1">'http://192.168.99.100:9200/_template/filebeat?pretty'</span> <span class="nt">-d</span>@/etc/filebeat/filebeat.template.json  
<span class="o">{</span>  
<span class="s2">"acknowledged"</span> : <span class="nb">true</span>  
<span class="o">}</span>  
</code></pre></div></div>

<p><strong>5) Start Filebeat daemon</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo</span> /etc/init.d/filebeat restart  
<span class="k">*</span> Restarting Sends log files to Logstash or directly to Elasticsearch. filebeat  
2016/01/19 10:55:36.335563 beat.go:97: DBG Initializing output plugins  
2016/01/19 10:55:36.337701 geolite.go:24: INFO GeoIP disabled: No paths were <span class="nb">set </span>under output.geoip.paths  
2016/01/19 10:55:36.406510 outputs.go:111: INFO Activated logstash as output plugin.  
2016/01/19 10:55:36.406694 publish.go:198: DBG create output worker: 0x0, 0x0  
2016/01/19 10:55:36.406901 publish.go:235: DBG No output is defined to store the topology. The server fields might not be filled.  
2016/01/19 10:55:36.407160 publish.go:249: INFO Publisher name: wso2-dev-srv-01  
2016/01/19 10:55:36.407587 async.go:95: DBG create bulk processing worker <span class="o">(</span><span class="nv">interval</span><span class="o">=</span>1s, bulk <span class="nv">size</span><span class="o">=</span>200<span class="o">)</span>  
2016/01/19 10:55:36.408164 beat.go:107: INFO Init Beat: filebeat<span class="p">;</span> Version: 1.0.1  
...done.  
</code></pre></div></div>

<p>or if You have created <code class="highlighter-rouge">filebeat.yml</code> in a different folder.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo</span> ./filebeat <span class="nt">-e</span> <span class="nt">-c</span> /myfolder/filebeat.yml  
</code></pre></div></div>

<p><strong>6) Check if Filebeat is running</strong></p>

<p>I have created a <code class="highlighter-rouge">filebeat.yml</code> file with the logs section enabled. That’s suitable to verify of everything is OK.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo tail</span> <span class="nt">-10000f</span> /var/log/filebeat/filebeat.log  
...  
2016-01-19T10:56:16Z DBG Start next scan  
2016-01-19T10:56:16Z DBG scan path /opt/wso2esb01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Check file <span class="k">for </span>harvesting: /opt/wso2esb01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Update existing file <span class="k">for </span>harvesting: /opt/wso2esb01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Not harvesting, file didn<span class="s1">'t change: /opt/wso2esb01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG scan path /opt/wso2esb02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Check file for harvesting: /opt/wso2esb02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Update existing file for harvesting: /opt/wso2esb02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Not harvesting, file didn'</span>t change: /opt/wso2esb02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG scan path /opt/wso2am02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Check file <span class="k">for </span>harvesting: /opt/wso2am02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Update existing file <span class="k">for </span>harvesting: /opt/wso2am02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Not harvesting, file didn<span class="s1">'t change: /opt/wso2am02a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG scan path /opt/wso2dss01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Check file for harvesting: /opt/wso2dss01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Update existing file for harvesting: /opt/wso2dss01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Not harvesting, file didn'</span>t change: /opt/wso2dss01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG scan path /opt/wso2greg01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Check file <span class="k">for </span>harvesting: /opt/wso2greg01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Update existing file <span class="k">for </span>harvesting: /opt/wso2greg01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:16Z DBG Not harvesting, file didn<span class="s1">'t change: /opt/wso2greg01a/repository/logs/wso2carbon.log  
2016-01-19T10:56:24Z DBG Flushing spooler because of timemout. Events flushed: 2  
2016-01-19T10:56:24Z DBG send event  
2016-01-19T10:56:24Z DBG Start Preprocessing  
2016-01-19T10:56:24Z DBG Publish: {  
"@timestamp": "2016-01-19T10:56:21.533Z",  
"beat": {  
"hostname": "wso2-dev-srv-01",  
"name": "wso2-dev-srv-01"  
},  
"count": 1,  
"fields": null,  
"input_type": "log",  
"message": "",  
"offset": 973,  
"source": "/opt/wiremock/wiremock.log",  
"type": "log"  
}  
2016-01-19T10:56:24Z DBG Publish: {  
"@timestamp": "2016-01-19T10:56:21.533Z",  
"beat": {  
"hostname": "wso2-dev-srv-01",  
"name": "wso2-dev-srv-01"  
},  
"count": 1,  
"fields": null,  
"input_type": "log",  
"message": "",  
"offset": 974,  
"source": "/opt/wiremock/wiremock.log",  
"type": "log"  
}  
2016-01-19T10:56:24Z DBG Forward preprocessed events  
2016-01-19T10:56:24Z DBG output worker: publish 2 events  
2016-01-19T10:56:24Z DBG Try to publish %!s(int=2) events to logstash with window size %!s(int=10)  
2016-01-19T10:56:24Z DBG %!s(int=2) events out of %!s(int=2) events sent to logstash. Continue sending ...  
2016-01-19T10:56:24Z INFO Events sent: 2  
2016-01-19T10:56:24Z DBG Processing 2 events  
2016-01-19T10:56:24Z DBG Write registry file: /.filebeat  
2016-01-19T10:56:24Z INFO Registry file updated. 6 states written.  
...  
</span></code></pre></div></div>

<p>The filebeat.log indicates that Filebeat daemon is sending the events to Logstash (ELK container).</p>

<p><strong>7) Viewing the raw log events from Kibana</strong></p>

<p>I am not filtering the log events, Logstash will be received the informations as it is.<br />
In a next blog post I will explain how to visualize the log events using filters, queries and graphs.
To view the raw log events, just open Kibana from a browser, in my case is in <code class="highlighter-rouge">http://192.168.99.100:5601</code>.<br />
Go to <code class="highlighter-rouge">Kibana &amp;gt; Settings</code>, add and create a new <code class="highlighter-rouge">Index Pattern</code> using the next:</p>
<ul>
  <li>Index name or pattern : <code class="highlighter-rouge">filebeat-*</code> (instead of <code class="highlighter-rouge">logstash-*</code>)</li>
  <li>Time-field name: <code class="highlighter-rouge">@timestamp</code>
After that, go to <code class="highlighter-rouge">Kibana &amp;gt; Discover</code> and select the recently created <code class="highlighter-rouge">filebeat-*</code> Index Pattern and You will see your logs/events.</li>
</ul>

<p><em>Kibana - Viewing WSO2 and Wiremock raw log events</em><br />
<img src="/assets/blog20160114_logs_elk_microservices_wso2/blog-chilcano-logs-wso2-docker-elk-rtail-4-kibana-esb-am-dss-wiremock-logs-discovery.png" alt="Kibana - Viewing WSO2 and Wiremock raw log events" /></p>

<p>In the above figure, a raw log event for WSO2 API Manager in JSON format is like as below:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span>  
<span class="s2">"_index"</span>: <span class="s2">"filebeat-2016.01.19"</span>,  
<span class="s2">"_type"</span>: <span class="s2">"log"</span>,  
<span class="s2">"_id"</span>: <span class="s2">"AVJZhXK2D7hOMrzuotcM"</span>,  
<span class="s2">"_score"</span>: null,  
<span class="s2">"_source"</span>: <span class="o">{</span>  
<span class="s2">"message"</span>: <span class="s2">"TID: [0] [AM] [2016-01-19 10:54:12,666] INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} - Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}"</span>,  
<span class="s2">"@version"</span>: <span class="s2">"1"</span>,  
<span class="s2">"@timestamp"</span>: <span class="s2">"2016-01-19T10:54:16.057Z"</span>,  
<span class="s2">"beat"</span>: <span class="o">{</span>  
<span class="s2">"hostname"</span>: <span class="s2">"wso2-dev-srv-01"</span>,  
<span class="s2">"name"</span>: <span class="s2">"wso2-dev-srv-01"</span>  
<span class="o">}</span>,  
<span class="s2">"count"</span>: 1,  
<span class="s2">"fields"</span>: null,  
<span class="s2">"input_type"</span>: <span class="s2">"log"</span>,  
<span class="s2">"offset"</span>: 0,  
<span class="s2">"source"</span>: <span class="s2">"/opt/wso2am02a/repository/logs/wso2carbon.log"</span>,  
<span class="s2">"type"</span>: <span class="s2">"log"</span>,  
<span class="s2">"host"</span>: <span class="s2">"wso2-dev-srv-01"</span>  
<span class="o">}</span>,  
<span class="s2">"fields"</span>: <span class="o">{</span>  
<span class="s2">"@timestamp"</span>: <span class="o">[</span>  
1453200856057  
<span class="o">]</span>  
<span class="o">}</span>,  
<span class="s2">"sort"</span>: <span class="o">[</span>  
1453200856057  
<span class="o">]</span>  
<span class="o">}</span>  
</code></pre></div></div>

<p>As I said above, in a next blog post I will explain how to visualize the log events using filters to parse simple event and multiple events.
That’s all.<br />
I hope you enjoyed it.</p>

<p><strong>References:</strong></p>
<ul>
  <li>Vagrant box with WSO2 stack and Wiremock (https://github.com/Chilcano/box-vagrant-wso2-dev-srv)</li>
  <li>Elasticsearch, Logstash, Kibana (ELK) Docker image by Sébastien Pujadas (https://github.com/spujadas/elk-docker)</li>
</ul>

  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/';
      this.page.identifier = 'https://holisticsecurity.io/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://holosec.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2016/01/19/log-events-management-wso2-microservices-elk-rtail-part-i/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading"><img src="/assets/img/logo-holosec.png" width="40" /> Holistic Security</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Holistic Security</li><li><a class="u-email" href="mailto:blog@holisticsecurity.io">blog@holisticsecurity.io</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/Chilcano"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">Chilcano</span></a></li><li><a href="https://www.linkedin.com/in/Chilcano"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">Chilcano</span></a></li><li><a href="https://www.twitter.com/Chilcano"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">Chilcano</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Systems Thinking, Holism, Trust, Security &amp; Usability.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
